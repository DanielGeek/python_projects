# ğŸš€ Daniel's Python Portfolio | Full-Stack Developer & AI Engineer

> **Building intelligent solutions with Python, Django, React, and cutting-edge AI technologies**

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![Django](https://img.shields.io/badge/Django-4.2-green.svg)](https://www.djangoproject.com/)
[![React](https://img.shields.io/badge/React-18.2-blue.svg)](https://reactjs.org/)
[![AI/ML](https://img.shields.io/badge/AI/ML-Llama%203-orange.svg)](https://ai.meta.com/llama/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-Ready-blue.svg)](https://www.postgresql.org/)

Welcome to my comprehensive Python portfolio showcasing progressive mastery from fundamental programming concepts to production-ready full-stack applications and AI-powered enterprise solutions.

---

## ğŸ“Š Portfolio Overview

This repository demonstrates my journey through **14 structured learning modules** and **11 production-scale projects**, encompassing:

- **ğŸ¯ 50+ Python programs** ranging from basic algorithms to complex systems
- **ğŸ¤– AI-Powered HR Management System** with Llama 3 integration
- **âš¡ Full-Stack Django-React Application** with JWT authentication
- **ğŸ¤– AI-Powered Meeting System** with real-time transcription and analysis
- **ğŸŒ¤ï¸ MCP Weather Servers** in TypeScript and Python with Claude Desktop integration
- **ğŸ¤– AI Data Generator Agent** with LangChain and Google Gemini for sample data generation
- **ğŸ§  21-RAG-AI Advanced RAG System** with Google Gemini, Inngest, and Streamlit
- **ğŸ” 22-AI-Search-Agent Multi-Source Research Agent** with Bright Data, Google Gemini, and Reddit integration
- **ğŸ”§ 23-AI-Agent Multi-LLM Evaluation System** with OpenAI, Google Gemini, Ollama, and real-time evaluation
- **ğŸ¤ 24-AI-Career-Assistant Professional AI Assistant** with tool use, Pushover notifications, and contextual responses
- **ğŸ­ 27-CrewAI-Debate Multi-Agent Debate System** with CrewAI, structured argumentation, and real-time debate orchestration
- **ğŸ’° 28-CrewAI-Financial-Researcher Real-Time Financial Analysis System** with CrewAI, SerperDevTool, and live market data integration
- **ğŸ“ˆ 29-CrewAI-Stock-Picker Intelligent Investment Analysis System** with CrewAI, hierarchical management, persistent memory, and real-time notifications
- **ğŸ’» 30-CrewAI-Coder AI-Powered Code Generation System** with CrewAI, Docker Code Interpreter, mathematical computations, and optimized execution
- **ğŸ—ï¸ 31-CrewAI-Engineering-Team AI Multi-Agent Software Engineering System** with specialized agents, complete application development, and production-ready code generation
- **ğŸ¤– 32-LangGraph-Chat Intelligent Chat System** with LangGraph state management, graph-based workflows, and Gradio interface
- **ğŸ” 33-LangGraph-Search Advanced AI Search System** with web search, push notifications, persistent memory, and tool integration
- **ğŸŒ 34-LangGraph-Playwright Advanced Web Scraping System** with anti-bot bypass, fresh browser contexts, and real-time content extraction
- **ğŸ¤ 35-LangGraph-Sidekick Multi-Agent Personal Co-worker** with Worker/Evaluator agents, structured outputs, and quality assurance loops
- **ğŸ”§ Enterprise-grade architecture** and best practices
- **ğŸ§ª Comprehensive testing** with pytest and modern testing frameworks

---

## ğŸ—ï¸ Flagship Projects

### 1. ğŸ¤– AI-Powered HR Management System

A cutting-edge HR platform leveraging Meta's Llama 3 70B for intelligent candidate screening

#### ğŸ¯ Key Features

- **AI Integration**: Real-time candidate shortlisting using Groq API + Llama 3 70B
- **Job Management**: Complete CRUD operations for HR personnel
- **Application Tracking**: Comprehensive applicant workflow system
- **File Management**: Secure CV upload and processing with PDF validation
- **Responsive Design**: Mobile-optimized Bootstrap 5 interface
- **Score-based Screening**: AI-powered candidate scoring (0-100 scale)
- **JSON Response Parsing**: Structured AI responses with validation

#### ğŸ› ï¸ Technical Implementation

```python
# AI-powered candidate evaluation using Llama 3
def consult_ai(job, cv_path):
    data = get_data(job=job, cv_path=cv_path)
    client = Groq(api_key=os.environ.get('GROQ_API_KEY'))
    completion = client.chat.completions.create(
        model="llama3-70b-8192",
        messages=[{
            "role": "user",
            "content": f"""You are an experienced HR assistant. 
            Given a resume, job responsibilities and required qualifications 
            you are supposed to rate that resume in a scale of 0 to 100 percent
            return your response in a python dictionary format with score and summary as keys"""
        }]
    )
    return parse_ai_response(response)
```

#### ğŸ“‹ Tech Stack

- **Backend**: Django 4.2, Django ORM
- **AI/ML**: Groq API, Meta Llama 3 70B, pypdf for CV processing
- **Frontend**: Bootstrap 5, Purple Admin Template
- **Database**: SQLite (dev), PostgreSQL ready (prod)
- **Testing**: pytest, pytest-django

#### ğŸš€ Production Features

- Environment-based configuration with .env support
- Secure file upload handling with PDF validation
- Database migrations and model relationships
- Admin interface for HR operations
- RESTful API design patterns
- Score-based candidate shortlisting (â‰¥80 threshold)
- JSON response validation and error handling

---

### 2. âš¡ Django-React Full-Stack Application

Modern SPA with secure JWT authentication and scalable architecture

#### ğŸ” Security & Authentication

- **JWT Token System**: Access/refresh token rotation
- **Password Security**: Django's built-in hashing
- **CORS Configuration**: Secure cross-origin requests
- **Input Validation**: Comprehensive data sanitization

#### ğŸ›ï¸ Architecture Highlights

```javascript
// React frontend with secure API integration
const api = axios.create({
  baseURL: 'http://localhost:8000/api',
  headers: {
    'Authorization': `Bearer ${getAccessToken()}`
  }
});

// Automatic token refresh
api.interceptors.response.use(
  response => response,
  async error => {
    if (error.response?.status === 401) {
      await refreshAccessToken();
      return api.request(error.config);
    }
    return Promise.reject(error);
  }
);
```

#### ğŸ› ï¸ Tech Stack

- **Backend**: Django REST Framework, Simple JWT
- **Frontend**: React 18, Vite, React Router
- **UI**: Tailwind CSS, Shadcn/ui, Lucide icons
- **Testing**: Vitest, React Testing Library
- **Database**: PostgreSQL production-ready

#### ğŸ“Š API Endpoints

- `/api/user/register/` - Secure user registration
- `/api/token/` - JWT token authentication
- `/api/token/refresh/` - Token rotation system
- Protected routes with middleware authentication

---

### 3. ğŸ¤– AI-Powered Meeting System

A comprehensive meeting automation platform with real-time transcription, AI analysis, and multi-platform integration

#### ğŸ¯ Meeting System Key Features

- **Real-time Transcription**: OpenAI Whisper integration for live meeting transcription
- **AI-Powered Analysis**: GPT-4 for meeting summaries, action items, and sentiment analysis
- **Multi-Platform Support**: Zoom, Google Meet, and Teams integration via Playwright automation
- **Bot Recorder**: Automated meeting recording without requiring platform SDKs
- **WebSockets**: Live transcription streaming to connected clients
- **OAuth Integration**: Secure authentication with meeting platforms
- **100% Python**: No Node.js or platform SDKs required

#### ğŸ› ï¸ Meeting System Technical Implementation

```python
# AI-powered meeting processing with MCP
def transcribe_audio_tool(video_url: str) -> str:
    """Transcribe meeting audio using OpenAI Whisper"""
    audio_path = download_video(video_url)
    transcript = transcribe_audio(audio_path)  # OpenAI Whisper
    return transcript

def summarize_meeting_tool(transcript: str) -> str:
    """Generate meeting summary using GPT-4"""
    summary = summarize_meeting(transcript)  # GPT-4 analysis
    actions = extract_action_items(transcript)
    return {
        "transcript": transcript,
        "summary": summary,
        "actions": actions
    }

# Bot Recorder with Playwright
async def _join_with_playwright(self):
    from playwright.async_api import async_playwright
    playwright = await async_playwright().start()
    browser = await playwright.chromium.launch()
    # Automatically joins meeting without SDK
```

#### ğŸ“‹ Meeting System Tech Stack

- **Backend**: FastAPI, WebSockets, Playwright
- **AI/ML**: OpenAI Whisper, GPT-4, FastMCP
- **Automation**: Playwright browser automation (100% Python)
- **Real-time**: WebSockets for live transcription (`/ws/transcript/{meeting_id}`)
- **Authentication**: OAuth 2.0 for meeting platforms
- **Architecture**: 2-file system (MCP_SERVER.py + MEETING_API.py)

#### ğŸš€ Meeting System Production Features

- Multi-threaded processing for concurrent meetings
- Secure file upload and processing
- Real-time WebSocket communication
- Comprehensive error handling and logging
- Production-ready deployment configuration
- No platform SDKs required (Playwright-based approach)
- OAuth integration with Zoom, Google Meet, Teams

---

### 4. ğŸŒ¤ï¸ MCP Weather Servers & AI Integration

Model Context Protocol (MCP) servers providing seamless integration with AI assistants like Claude Desktop, featuring advanced authentication and real-time data processing

#### ğŸ¯ MCP Servers Key Features

- **Dual Implementation**: TypeScript and Python versions for different ecosystems
- **MCP Protocol**: JSON-RPC 2.0 communication via stdio
- **Weather Data**: Integration with National Weather Service API
- **AI Assistant Integration**: Works with Claude Desktop and Windsurf
- **Real-time Data**: Weather alerts and forecasts for any US location
- **Cross-platform**: Compatible with Windows, macOS, and Linux
- **Advanced Authentication**: OAuth 2.0 with Auth0 integration
- **Cloudflare Workers**: Production-ready deployment on serverless platform
- **Remote MCP**: Secure remote server connections with token management
- **Context Engineering**: Optimized token usage and context management
- **Agent Skills**: Multi-agent systems with specialized capabilities

#### ğŸ› ï¸ MCP Servers Technical Implementation

```python
# Python MCP Server with FastMCP
@mcp.tool(name="get-forecast")
async def get_forecast(latitude: float, longitude: float) -> str:
    """Get weather forecast for coordinates."""
    url = f"{NWS_API_BASE}/points/{latitude},{longitude}"
    data = await make_nws_request(url)
    return format_forecast(data)

@mcp.tool(name="get-alerts") 
async def get_alerts(state: str) -> str:
    """Get weather alerts for a US state."""
    url = f"{NWS_API_BASE}/alerts/active/area/{state}"
    data = await make_nws_request(url)
    return format_alerts(data)
```

#### ğŸ“‹ MCP Servers Tech Stack

- **Python Version**: FastMCP, httpx, uv package management
- **TypeScript Version**: Node.js, npm, TypeScript compilation
- **Protocol**: JSON-RPC 2.0 over stdio
- **API Integration**: National Weather Service REST API
- **Authentication**: OAuth 2.0, Auth0, JWT token management
- **Deployment**: Cloudflare Workers, serverless architecture
- **Remote Access**: mcp-remote CLI tool for secure connections
- **Context Optimization**: FastMCP 2.12.4+ with advanced features
- **Multi-Agent**: LangChain integration with agent orchestration

#### ğŸš€ Advanced Features

- **Auth0 Integration**: Complete OAuth 2.0 flow with PKCE
- **Cloudflare Deployment**: Serverless MCP servers with global distribution
- **Remote Authentication**: Secure token-based remote MCP connections
- **Context Engineering**: Optimized token usage for AI assistants
- **Multi-Agent Systems**: Specialized agents for different tasks
- **Real-time Processing**: WebSocket connections for live data
- **Production Monitoring**: Comprehensive logging and error handling
- **Enterprise Security**: Role-based access control and audit logging

---

### 5. ğŸ¤– AI Data Generator Agent

An intelligent AI agent built with LangChain that generates realistic sample user data for applications and testing purposes, featuring natural language processing and structured JSON output generation.

#### ğŸ¯ AI Data Generator Key Features

- **Natural Language Interface**: Conversational commands for data generation using Google Gemini 2.5 Flash
- **Structured JSON Output**: Complete user profiles with ID, names, email, username, age, registration dates
- **Smart Parameter Inference**: Automatically fills in names, domains, and age ranges based on context
- **File Operations**: Read/write JSON files with proper formatting and validation
- **Customizable Data**: Control age ranges, email domains, specific names, and more
- **Real-time Processing**: Instant data generation with AI-powered understanding
- **Production Ready**: Error handling, logging, and comprehensive documentation

#### ğŸ› ï¸ AI Data Generator Technical Implementation

```python
# AI-powered data generation with LangChain
@tool
def generate_sample_users(
    first_names: List[str],
    last_names: List[str],
    domains: List[str],
    min_age: int,
    max_age: int
) -> dict:
    """Generate sample user data with complete profiles"""
    users = []
    for i in range(len(first_names)):
        user = {
            "id": i + 1,
            "firstName": first_names[i],
            "lastName": last_names[i % len(last_names)],
            "email": f"{first_names[i].lower()}.{last_names[i % len(last_names)].lower()}@{domains[i % len(domains)]}",
            "username": f"{first_names[i].lower()}{random.randint(100, 999)}",
            "age": random.randint(min_age, max_age),
            "registeredAt": (datetime.now() - timedelta(days=random.randint(1, 365))).isoformat()
        }
        users.append(user)
    return {"users": users, "count": len(users)}

# Natural language processing with Google Gemini
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash")
agent = create_agent(llm, TOOLS, system_prompt=SYSTEM_MESSAGE)
```

#### ğŸ“‹ AI Data Generator Tech Stack

- **AI Framework**: LangChain with Google Gemini 2.5 Flash integration
- **Data Processing**: Pydantic for validation, JSON for structured output
- **Package Management**: UV for modern Python dependency management
- **Natural Language**: Advanced prompt engineering for context understanding
- **File Operations**: JSON read/write with error handling and validation
- **Architecture**: Tool-based design with extensible function system

#### ğŸš€ AI Data Generator Production Features

- Conversational interface for non-technical users
- Automatic parameter inference from natural language
- Comprehensive error handling and user feedback
- Extensible tool system for additional data types
- Production-ready logging and monitoring
- Complete documentation and examples
- Cross-platform compatibility (Windows, macOS, Linux)

#### ğŸ’¡ CLI Agent Example Usage

```bash
# Start the agent
uv run main.py

# Natural language commands
You: generate 5 random users
You: make users aged 25-35 with company.com emails and save 3 of them to users.json
You: what is the oldest user in users.json?
```

---

### 6. ğŸ§  21-RAG-AI: Advanced Retrieval-Augmented Generation System

A sophisticated event-driven RAG application demonstrating modern AI integration patterns with Google Gemini, Inngest, Qdrant, and Streamlit for intelligent document processing and querying.

#### ğŸ¯ RAG System Key Features

- **Google Gemini 2.5 Flash Integration**: Advanced LLM for intelligent responses with text-embedding-004
- **Event-Driven Architecture**: Scalable processing with Inngest for async workflows
- **Vector Database**: Qdrant for high-performance similarity search and storage
- **Real-time Processing**: Live PDF ingestion, chunking, and embedding generation
- **Beautiful UI**: Streamlit frontend for document upload and intelligent querying
- **Semantic Search**: Advanced embedding-based retrieval with source attribution
- **Production Ready**: Type safety, error handling, and comprehensive logging

#### ğŸ› ï¸ RAG System Technical Implementation

```python
# Event-driven PDF ingestion with Inngest
@inngest_client.create_function(
    fn_id="RAG: Ingest PDF",
    trigger=inngest.TriggerEvent(event="rag/ingest_pdf"),
)
async def rag_ingest_pdf(ctx: inngest.Context):
    # Load and chunk PDF
    chunks_and_src = await ctx.step.run("load-and-chunk", lambda: _load(ctx))
    # Generate embeddings and store in Qdrant
    ingested = await ctx.step.run("embed-and-upsert", lambda: _upsert(chunks_and_src))
    return ingested.model_dump()

# Intelligent querying with context
@inngest_client.create_function(
    fn_id="RAG: Query PDF", 
    trigger=inngest.TriggerEvent(event="rag/query_pdf_ai"),
)
async def rag_query_pdf_ai(ctx: inngest.Context):
    # Embed question and search vectors
    found = await ctx.step.run("embed-and-search", lambda: _search(question, top_k))
    # Generate contextual response with Gemini
    answer = await ctx.step.run("llm-answer", lambda: _generate_answer(user_content))
    return {"answer": answer, "sources": found.sources}
```

#### ğŸ“‹ RAG System Tech Stack

- **AI/ML**: Google Gemini 2.5 Flash, text-embedding-004 (768 dimensions)
- **Backend**: FastAPI with async/await, Inngest for event-driven processing
- **Vector DB**: Qdrant for similarity search and vector storage
- **Frontend**: Streamlit for beautiful, responsive web interface
- **Package Management**: UV for modern Python dependency management
- **Architecture**: Event-driven microservices with type safety

#### ğŸš€ RAG System Production Features

- Multi-terminal architecture (FastAPI + Inngest + Qdrant + Streamlit)
- Real-time PDF processing with automatic chunking and embedding
- Semantic search with configurable retrieval parameters
- Comprehensive error handling and status monitoring
- Type-safe implementation with Pydantic models
- Hot reloading for fast development cycles
- Docker-ready deployment configuration

#### ğŸ’¡ Vector Database Example Usage

```bash
# Terminal 1: Start Qdrant vector database
docker run -d --name qdrant-rag -p 6333:6333 qdrant/qdrant:latest

# Terminal 2: Start FastAPI backend with Inngest
uv run uvicorn main:app --reload

# Terminal 3: Start Inngest dev server
npx inngest-cli@latest dev -u http://127.0.0.1:8000/api/inngest

# Terminal 4: Start Streamlit frontend
uv run streamlit run streamlit_app.py

# Use the web interface at http://localhost:8501
# Upload PDFs and ask intelligent questions about your documents
```

---

### 7. ğŸ” 22-AI-Search-Agent: Multi-Source Research Agent

An intelligent multi-source research agent that leverages multiple search engines and social media platforms to provide comprehensive, well-analyzed answers to user queries.

#### ğŸ¯ AI Search Agent Key Features

- **Multi-Source Intelligence**: Google, Bing, and Reddit search with unified analysis
- **Bright Data Integration**: Professional-grade web scraping with SERP and Reddit APIs
- **LangGraph Workflow**: Complex multi-step research orchestration with state management
- **Google Gemini AI**: Advanced reasoning and synthesis from multiple data sources
- **Structured Data Processing**: Pydantic models for type-safe data handling
- **Real-time Progress Tracking**: Asynchronous snapshot polling and download management
- **Comprehensive Analysis**: Individual source analysis with final intelligent synthesis

#### ğŸ› ï¸ AI Search Agent Technical Implementation

```python
# Multi-source search orchestration with LangGraph
def search_google(state: State):
    query = state.get("user_question", "")
    google_results = serp_search(query, engine="google")
    return {"google_results": google_results}

def search_bing(state: State):
    query = state.get("user_question", "")
    bing_results = serp_search(query, engine="bing")
    return {"bing_results": bing_results}

def search_reddit(state: State):
    query = state.get("user_question", "")
    reddit_results = reddit_search_api(query)
    return {"reddit_results": reddit_results}

# AI-powered URL selection and content extraction
def analyze_reddit_urls(state: State):
    reddit_results = state.get("reddit_results", "")
    messages = get_reddit_url_analysis_messages(reddit_results)
    structured_llm = llm.with_structured_output(RedditURLAnalysis)
    analysis = structured_llm.invoke(messages)
    return {"selected_reddit_urls": analysis.selected_urls}
```

#### ğŸ“‹ AI Search Agent Tech Stack

- **AI Framework**: LangChain with Google Gemini 2.5 Flash integration
- **Workflow Orchestration**: LangGraph for complex multi-step processes
- **Web Scraping**: Bright Data SERP API and Reddit Datasets API
- **Data Processing**: Pydantic models, structured outputs, JSON handling
- **Package Management**: UV for modern Python dependency management
- **Architecture**: State-based workflow with parallel processing

#### ğŸš€ AI Search Agent Production Features

- Parallel multi-source data collection for faster results
- Configurable retry logic and timeout handling for API reliability
- Intelligent URL selection using structured LLM outputs
- Comprehensive error handling with graceful degradation
- Real-time progress tracking and user feedback
- Type-safe implementation with full Pydantic validation
- Extensible architecture for additional search sources

#### ğŸ’¡ Multi-Source Example Usage

```bash
# Setup and run the multi-source research agent
cd 22-AI-Search-Agent
uv sync
cp .env.example .env
# Edit .env with Bright Data and Google API keys
uv run main.py

# Example research queries
Ask me anything: invest in NVIDIA
Ask me anything: best programming languages for AI development
Ask me anything: climate change impact on technology
```

### 8. ğŸ¤– 24-AI-Career-Assistant: Advanced Multi-Model AI Career Assistant

A sophisticated AI career assistant powered by Google Gemini models with advanced multi-model rotation, session tracking, and comprehensive API management system.

#### ğŸ¯ Key Features

- **Multi-Model AI Chat**: Intelligent conversation using Google's free Gemini models
- **4-Model Rotation System**: Automatic switching between gemini-2.5-flash, gemini-2.0-flash, gemini-2.5-flash-lite, and gemini-2.0-flash-lite
- **Smart Rate Limiting**: Exponential backoff with automatic retry logic (1min â†’ 30min)
- **Session Tracking**: UUID-based session tracking for user interaction analytics
- **Real-time Notifications**: Pushover integration with complete API usage statistics
- **Career Showcase**: Displays Daniel's 12+ years of software development expertise
- **Smart Tool Integration**: Automatic detection of unknown questions, contact requests, and job offers

#### ğŸ› ï¸ Technical Implementation

```python
# Advanced API Management with Multi-Model Rotation
class APIKeyModelManager:
    def __init__(self):
        self.keys = self._load_api_keys()
        self.models = FREE_MODELS  # 4 Gemini models
        self.usage_per_combination = {}  # Track per (key, model) usage
        
    def increment_usage(self):
        """Increment usage for current key and model combination"""
        combo = (self.current_key_index, self.current_model_index)
        if combo not in self.usage_per_combination:
            self.usage_per_combination[combo] = 0
        self.usage_per_combination[combo] += 1
        
    def get_usage_stats(self):
        """Display real-time usage statistics per model+key combination"""
        # Shows per-model usage with proper reset on model switch
        return comprehensive_usage_display

# Session-aware tool calling with tracking
def handle_tool_call(self, tool_calls):
    results = []
    for tool_call in tool_calls:
        tool_name = tool_call.function.name
        arguments = json.loads(tool_call.function.arguments)
        # Add session_id to all tool calls for tracking
        arguments['session_id'] = self.session_id
        tool = globals().get(tool_name)
        result = tool(**arguments) if tool else {}
        results.append({
            "role": "tool",
            "content": json.dumps(result),
            "tool_call_id": tool_call.id
        })
    return results
```

#### ğŸ”§ Advanced Features

**Multi-Model Rotation Logic:**

- **gemini-2.5-flash**: Best quality, hybrid reasoning, 1M context
- **gemini-2.0-flash**: Multimodal, agent-ready, 1M context  
- **gemini-2.5-flash-lite**: Cost-effective, high throughput
- **gemini-2.0-flash-lite**: Fastest, most economical

**Session Management:**

```python
# UUID-based session tracking
self.session_id = str(uuid.uuid4())

# Enhanced push notifications with session context
def push(text, session_id=None, user_context=None):
    full_message = text + "\n\n" + "="*40
    full_message += f"\nğŸ“ Session ID: {session_id[:8]}..."
    full_message += f"\nâ€¢ Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
    full_message += f"\n\nğŸ”‘ Gemini API Usage:\n{api_manager.get_usage_stats()}"
```

**Intelligent Tool Detection:**

- `record_unknown_question`: Captures questions outside Daniel's expertise
- `record_user_details`: Handles contact information and networking requests  
- `record_job_offer`: Processes job opportunities with compensation details

#### ğŸ“Š Real-time Usage Monitoring

```text
ğŸ¤– Current Model: gemini-2.5-flash
ğŸ”‘ Current Key: 3

Key 1: 20/20 used âš ï¸ (1/4 models exhausted) (resets in 23h 59m)
Key 2: 15/20 used âœ…
Key 3: 3/20 used âœ…
Key 4: 0/20 used âœ…
```

#### ğŸš€ Production Features

**API Management:**

- **Per-model usage tracking**: Independent counters for each model+key combination
- **Automatic rotation**: Seamless switching when quotas are exhausted
- **Backoff strategy**: Exponential backoff for rate limit handling
- **Error recovery**: Comprehensive error handling with automatic retry

**Professional Applications:**

- **Career Networking**: Automated response to professional inquiries
- **Job Opportunity Detection**: Immediate notification of relevant positions
- **Knowledge Gap Analysis**: Identify topics to expand expertise
- **Business Development**: Lead capture and qualification system

#### ğŸ’¡ Career Assistant Example Usage

```bash
# Setup and run the advanced AI career assistant
cd 24-AI-Career-Assistant
uv sync
cp .env.example .env
# Edit .env with 4 Google Gemini API keys and Pushover credentials
uv run daniel-chatbot.py

# Available at http://127.0.0.1:7860 or https://[random-id].gradio.live

# Example interactions:
# "What experience do you have with AI and blockchain development?"
# "I'm recruiting for a senior Python position at JP Morgan"
# "Can you help me understand your consulting rates and availability?"
```

#### ğŸ¯ Enterprise-Ready Capabilities

- **Multi-API Key Management**: Load balancing across 4 Gemini API keys
- **Session Analytics**: Complete interaction tracking with UUID-based sessions
- **Real-time Monitoring**: Live usage statistics and API quota management
- **Professional Branding**: Tailored for Daniel's 12+ years software development experience
- **Mobile Notifications**: Instant alerts with comprehensive usage analytics

---

### 9. ğŸ¤– 25-OpenAI-Agent: Multi-Model Automated SDR System

A sophisticated multi-model AI agent system leveraging OpenAI Agents SDK for automated sales development representative (SDR) workflows with intelligent model rotation and complete email automation pipeline.

#### ğŸ¯ Key Features

- **Multi-Model AI Agents**: DeepSeek, Gemini, Llama3.3, and OpenAI models with intelligent fallback rotation
- **Automated Email Generation**: Three specialized email styles (professional, humorous, concise) with real-time generation
- **Smart Model Rotation**: 4-attempt fallback system (Primary â†’ OpenAI â†’ Other1 â†’ Other2) with comprehensive error handling
- **Complete Email Workflow**: Generation â†’ Selection â†’ Subject Writing â†’ HTML Conversion â†’ Email Sending
- **Input Guardrails**: Advanced name detection and validation system for security compliance
- **Real-time Tracing**: Full OpenAI dashboard visibility for all model attempts and executions
- **Resend Integration**: Professional email delivery with HTML formatting and delivery confirmation
- **Enterprise Error Handling**: Graceful handling of API failures (402, 403, 429) with automatic retry logic

#### ğŸ› ï¸ Technical Implementation

```python
# Multi-model rotation with real execution and tracing
async def _run_agent_with_rotation(tool_name: str, instructions: str, input_text: str, model_sequence: list) -> str:
    """Try each model in sequence until one succeeds. Each attempt appears in traces."""
    for i, (model, model_name) in enumerate(model_sequence):
        try:
            print(f"  ğŸ”„ [{tool_name}] Attempt {i+1}/4: Trying {model_name}...")
            agent = Agent(name=f"{model_name} Sales Agent", instructions=instructions, model=model)
            result = await Runner.run(agent, input_text)  # Real model execution
            print(f"  âœ… [{tool_name}] {model_name} succeeded!")
            return result.final_output
        except Exception as e:
            print(f"  âŒ [{tool_name}] {model_name} failed: {str(e)[:80]}")
            continue  # Rotate to next model

# Input guardrails for security
@input_guardrail
async def guardrail_against_name(ctx, agent, message):
    result = await Runner.run(guardrail_agent, message, context=ctx.context)
    is_name_in_message = result.final_output.is_name_in_message
    return GuardrailFunctionOutput(
        output_info={"found_name": result.final_output},
        tripwire_triggered=is_name_in_message
    )
```

#### ğŸ“‹ Tech Stack

- **AI Framework**: OpenAI Agents SDK with multi-model support
- **Models**: DeepSeek, Gemini, Llama3.3, OpenAI gpt-4o-mini with rotation logic
- **Email Service**: Resend API with HTML formatting and delivery tracking
- **Security**: Input guardrails with name detection and validation
- **Monitoring**: Real-time tracing with OpenAI dashboard integration
- **Package Management**: UV for modern Python dependency management

#### ğŸš€ Advanced Features

**Model Rotation Strategy:**

```python
# Each tool attempts models in different orders for diversity
TOOL1: DeepSeek â†’ OpenAI â†’ Gemini â†’ Llama3.3
TOOL2: Gemini â†’ OpenAI â†’ Llama3.3 â†’ DeepSeek  
TOOL3: Llama3.3 â†’ OpenAI â†’ DeepSeek â†’ Gemini
```

**Complete Workflow:**

1. **Input Validation**: Guardrail agent checks for personal information
2. **Email Generation**: 3 sales agents create different style drafts
3. **Model Rotation**: Each agent tries 4 models until success
4. **Selection**: Sales Manager selects best email draft
5. **Email Processing**: Subject writing + HTML conversion
6. **Delivery**: Email sent via Resend with confirmation

**Error Handling:**

- **402 Insufficient Balance**: Automatic rotation to next model
- **403 Access Denied**: Seamless transition to backup model
- **429 Rate Limit**: Intelligent retry with exponential backoff
- **Max Turns Exceeded**: Fallback to next Sales Manager model

#### ğŸ’¡ Multi-Model SDR Example Usage

```bash
# Setup and run the multi-model automated SDR system
cd 25-openai-agent
uv sync
cp .env.example .env
# Edit .env with API keys (OpenAI, Google, DeepSeek, Groq, Resend)
uv run main.py

# Example output with model rotation:
ğŸ”„ [TOOL1] Starting multi-model rotation (DeepSeek -> OpenAI -> Gemini -> Llama3.3)
  ğŸ”„ [TOOL1] Attempt 1/4: Trying DeepSeek...
  âŒ [TOOL1] DeepSeek failed: Error code: 402 - Insufficient Balance
  ğŸ”„ [TOOL1] Attempt 2/4: Trying OpenAI...
  âœ… [TOOL1] OpenAI succeeded!

âœ… [SALES_MGR] Handoff successful! Sales Manager â†’ Email Manager
ğŸ“§ [SALES_MGR] Email should have been processed and sent by Email Manager
```

#### ğŸ¯ Enterprise-Ready Capabilities

- **Multi-API Management**: Load balancing across 4 different AI providers
- **Real-time Monitoring**: Complete visibility into model attempts and success rates
- **Security Compliance**: Input validation with guardrail protection
- **Production Logging**: Comprehensive error tracking and performance metrics
- **Email Automation**: Professional delivery with HTML formatting and tracking

---

### 7. ğŸ­ 27-CrewAI-Debate: Multi-Agent Debate System

A sophisticated multi-agent debate system powered by CrewAI that simulates structured debates on complex topics with AI agents taking different positions and providing objective analysis.

#### ğŸ¯ Key Features

- **Multi-Agent Architecture**: Three specialized AI agents (Pro-Regulation, Anti-Regulation, Moderator)
- **Structured Debate Flow**: Opening arguments â†’ Context-aware rebuttals â†’ Final analysis
- **Real-time Tracing**: Built-in execution tracing with CrewAI Cloud integration
- **Customizable Topics**: Easy to modify debate subjects and agent configurations
- **Context-Aware Responses**: Agents reference previous arguments in rebuttals
- **Objective Moderation**: Independent moderator evaluates both sides comprehensively

#### ğŸ› ï¸ Technical Implementation

```python
# Crew orchestration with sequential process
crew = Crew(
    agents=[pro_agent, anti_agent, moderator],
    tasks=[pro_task, anti_task, pro_rebuttal, anti_rebuttal, moderator_task],
    process=Process.sequential,
    verbose=True
)

# Execute debate with real-time tracing
result = crew.kickoff()
```

#### ğŸ“‹ Tech Stack

- **Framework**: CrewAI 1.8+ with multi-agent orchestration
- **AI/ML**: OpenAI GPT models (gpt-4o-mini, gpt-4, etc.)
- **Configuration**: YAML-based agent and task definitions
- **Tracing**: CrewAI Cloud integration for debugging and monitoring
- **Package Management**: UV with Python 3.12 compatibility

#### ğŸ­ Debate Structure

1. **Opening Arguments** (300-400 words each)
   - Pro-regulation advocate presents comprehensive case
   - Anti-regulation advocate presents counter-arguments

2. **Context-Aware Rebuttals** (200-300 words each)
   - Each agent addresses specific points from opposition
   - Builds upon previous arguments with evidence

3. **Final Analysis** (400-500 words)
   - Moderator evaluates both sides objectively
   - Identifies strongest arguments and logical fallacies
   - Provides balanced conclusion

#### ğŸ’¡ Example Usage

```bash
# Setup CrewAI CLI with Python 3.12
uv tool install crewai --python 3.12

# Create and setup project
crewai create crew debate-ai
cd debate-ai
crewai install

# Configure environment
cp .env.example .env
# Edit .env with OPENAI_API_KEY

# Run structured debate
crewai run

# Enable tracing for debugging
crewai traces enable
```

#### ğŸ¯ Advanced Capabilities

- **Extensible Architecture**: Add more agents and debate topics
- **Knowledge Integration**: Support for external knowledge bases
- **Real-time Monitoring**: Complete visibility into agent interactions
- **Custom LLM Support**: Compatible with OpenAI, Anthropic, Groq, and more
- **YAML Configuration**: Easy modification of agents and tasks without code changes

#### ğŸ“Š Example Output

The system generates comprehensive debate outputs:

- **Structured Arguments**: Evidence-based positions with clear reasoning
- **Intelligent Rebuttals**: Context-aware responses to opposition points
- **Objective Analysis**: Balanced evaluation with identification of logical fallacies
- **Trace Reports**: Detailed execution logs for debugging and improvement

---

### 8. ğŸ’° 28-CrewAI-Financial-Researcher: Real-Time Financial Analysis System

A sophisticated financial research and analysis system powered by CrewAI that provides up-to-date company analysis using real-time web searches and professional financial reporting.

#### ğŸ¯ Key Features

- **Real-Time Data Integration**: Live stock prices, recent news, earnings reports, and market analysis via SerperDevTool
- **Multi-Agent Architecture**: Senior Financial Researcher (web search specialist) and Market Analyst (report generation)
- **Professional Financial Reporting**: Structured reports with executive summary, current status, developments, analysis, and outlook
- **Source Verification**: All data includes citations and publication dates for credibility
- **Date-Specific Context**: Every data point includes temporal information for accuracy

#### ğŸ› ï¸ Technical Implementation

```python
# Financial research with real-time web searches
class FinancialResearcher:
    @agent
    def researcher(self) -> Agent:
        return Agent(
            config=self.agents_config['researcher'],
            tools=[SerperDevTool()],  # Real-time web search
            verbose=True
        )
    
    def run(self):
        inputs = {
            'company': 'Tesla',
            'year': datetime.now().year  # Current year
        }
        return self.crew().kickoff(inputs=inputs)
```

#### ğŸ“‹ Tech Stack

- **Framework**: CrewAI 1.8+ with multi-agent orchestration
- **AI/ML**: OpenAI GPT models for analysis and reporting
- **Real-Time Search**: SerperDevTool for live financial data and news
- **Configuration**: YAML-based agent and task definitions with mandatory search queries
- **Output Generation**: Professional markdown reports with source citations

#### ğŸ” Research Process

1. **Mandatory Web Searches**: Research agent performs 5 required searches:
   - `"{company} stock price {year}"`
   - `"{company} earnings report {year}"`
   - `"{company} news {year}"`
   - `"{company} financial results {year}"`
   - `"{company} market analysis {year}"`

2. **Data Collection**: Gathers current financial data, stock prices, recent news
3. **Professional Analysis**: Creates comprehensive report with insights and projections

#### ğŸ’¡ Example Usage

```bash
# Setup CrewAI CLI with Python 3.12
uv tool install crewai --python 3.12

# Create and setup project
crewai create crew financial-researcher
cd financial-researcher
crewai install

# Configure environment
cp .env.example .env
# Edit .env with OPENAI_API_KEY and SERPER_API_KEY

# Run financial analysis
crewai run

# Output: Comprehensive financial report with current data
# Tesla Company Analysis Report - 2026
# - Stock Price: $437.86 (as of January 16, 2026)
# - Recent Financial Results: 589,000 vehicles delivered in 2025
# - Market Analysis: Current analyst projections and trends
```

#### ğŸ¯ Advanced Capabilities

- **Customizable Companies**: Analyze any publicly traded company
- **Year-Specific Analysis**: Focus on current year or historical periods
- **Extensible Search**: Add custom search queries for specific financial data
- **Professional Formatting**: Structured markdown reports with proper citations
- **Real-Time Verification**: All data includes sources and publication dates

#### ğŸ“Š Example Output

The system generates professional financial reports with:
- **Current Data**: Real-time stock prices and market metrics
- **Recent News**: Latest announcements and developments
- **Financial Analysis**: Professional insights and trend analysis
- **Source Citations**: All data includes sources and dates
- **Future Projections**: Analyst expectations and market outlook

#### ğŸš€ Production Features

- **Error Handling**: Graceful handling of API limits and search failures
- **Data Validation**: Verification of financial data accuracy and recency
- **Professional Output**: Structured reports suitable for business use
- **Extensible Architecture**: Easy to add new search queries and analysis types

---

### 9. ğŸ“ˆ 29-CrewAI-Stock-Picker: Intelligent Investment Analysis System

A sophisticated multi-agent AI system powered by CrewAI that performs comprehensive financial analysis, identifies trending companies, and makes data-driven investment recommendations with real-time market intelligence and persistent learning capabilities.

#### ğŸ¯ Key Features

- **Multi-Agent Architecture**: Manager orchestrates Financial News Analyst, Senior Financial Researcher, and Stock Picker agents
- **Advanced Memory Systems**: Short-term, long-term, and entity memory with ChromaDB vector storage and SQLite persistence
- **Hierarchical Process**: Manager delegates tasks and coordinates workflow for optimal decision-making
- **Real-Time Market Intelligence**: SerperDevTool integration for live web searches and current market data
- **Smart Notifications**: Instant investment recommendations via Pushover with custom branding (ğŸ“ˆ AI Stock Picker)
- **Professional Output Generation**: JSON reports with structured data and markdown decisions with detailed rationale

#### ğŸ› ï¸ Technical Implementation

```python
# Advanced memory systems for persistent learning
class StockPicker:
    @crew
    def crew(self) -> Crew:
        manager = Agent(
            config=self.agents_config['manager'],
            allow_delegation=True
        )
        
        return Crew(
            agents=self.agents,
            tasks=self.tasks,
            process=Process.hierarchical,  # Manager coordination
            memory=True,
            short_term_memory=short_term_memory,    # ChromaDB embeddings
            long_term_memory=long_term_memory,      # SQLite persistence
            entity_memory=entity_memory,            # Entity extraction
            manager_agent=manager
        )
```

#### ğŸ“‹ Tech Stack

- **Framework**: CrewAI 1.8+ with hierarchical multi-agent orchestration
- **AI/ML**: OpenAI GPT models for analysis and decision-making
- **Memory Systems**: ChromaDB (vector embeddings) + SQLite (structured persistence)
- **Real-Time Search**: SerperDevTool for live financial data and market intelligence
- **Notifications**: Pushover API for instant investment recommendations
- **Data Processing**: Pydantic models for structured JSON validation

#### ğŸ§  Memory Architecture

**Three-Layer Memory System:**
1. **Short-Term Memory**: ChromaDB with OpenAI embeddings for recent conversations
2. **Long-Term Memory**: SQLite database for persistent knowledge and historical insights
3. **Entity Memory**: Vector embeddings for companies, relationships, and semantic connections

**Learning Benefits:**
- Session 1: Analyzes Tesla â†’ Stores EV market insights
- Session 2: Analyzes Rivian â†’ Recalls Tesla patterns for comparison
- Session 3: Analyzes Lucid â†’ Compares with all previous EV analysis

#### ğŸ” Investment Analysis Workflow

1. **Trending Company Discovery**: Real-time news search for current market trends
2. **Deep Financial Research**: Company-specific analysis with market position and outlook
3. **Investment Decision Making**: Comparative analysis with risk-adjusted selection
4. **Instant Notification**: Push notification with decision and rationale

#### ğŸ’¡ Example Usage

```bash
# Setup CrewAI CLI with Python 3.12
uv tool install crewai --python 3.12

# Create and setup project
crewai create crew stock-picker
cd stock-picker
crewai install

# Configure environment
cp .env.example .env
# Edit .env with OPENAI_API_KEY, SERPER_API_KEY, PUSHOVER_USER, PUSHOVER_TOKEN

# Run investment analysis
crewai run

# Output: Comprehensive investment analysis with memory-enhanced insights
# ğŸ“± Push Notification: ğŸ“ˆ AI Stock Picker - Perplexity AI selected for investment
# ğŸ“Š Files: trending_companies.json, research_report.json, decision.md
```

#### ğŸ¯ Advanced Capabilities

- **Persistent Learning**: Memory systems learn from each analysis session
- **Hierarchical Management**: Manager coordinates agent delegation and quality control
- **Real-Time Intelligence**: Live market data with current year context
- **Entity Recognition**: Automatic extraction of companies and relationships
- **Investment Tracking**: Historical decision analysis and performance comparison
- **Customizable Sectors**: Analyze any market sector (Technology, Healthcare, etc.)

#### ğŸ“Š Example Output

The system generates comprehensive investment analysis:
- **Trending Companies**: JSON list with current market trends and reasoning
- **Research Reports**: Detailed financial analysis with market position and outlook
- **Investment Decisions**: Rationale for selection and rejected alternatives
- **Memory-Enhanced Insights**: Comparisons with previous analyses and learned patterns

#### ğŸš€ Production Features

- **Error Handling**: Robust JSON validation and trailing comma prevention
- **Memory Management**: Efficient ChromaDB and SQLite storage systems
- **Data Validation**: Source verification and citation requirements
- **Scalable Architecture**: Modular agent and task configuration
- **Professional Output**: Investment-grade analysis with structured reporting

---

### 10. ğŸ’» 30-CrewAI-Coder: AI-Powered Code Generation & Execution System

A sophisticated multi-agent AI system powered by CrewAI that generates, executes, and validates Python code with real-time Docker-based code interpretation, optimized for computational tasks and mathematical calculations.

#### ğŸ¯ Key Features

- **Docker Code Interpreter**: Secure code execution in isolated Docker containers with automatic lifecycle management
- **Optimized Performance**: 120-second execution window with retry logic and comprehensive error handling
- **Intelligent Code Generation**: Natural language to Python code conversion with mathematical computation capabilities
- **Professional Output Management**: Structured results with file generation and execution tracing

#### ğŸ› ï¸ Technical Implementation

```python
@agent
def coder(self) -> Agent:
    return Agent(
        config=self.agents_config['coder'],
        verbose=True,
        allow_code_execution=True,        # Enables Code Interpreter
        code_execution_mode="safe",       # Uses Docker containers
        max_execution_time=120,          # Optimized timeout
        max_retry_limit=5,               # Retry failed executions
    )
```

#### ğŸ“‹ Tech Stack

- **Framework**: CrewAI 1.8+ with code execution capabilities
- **AI/ML**: OpenAI GPT models for code generation and problem solving
- **Docker Integration**: Secure containerized code execution environment
- **Performance**: Optimized timeout management and retry mechanisms
- **Output Management**: Structured code generation with execution results

#### ğŸ³ Docker Code Interpreter Architecture

**Secure Execution Environment:**
- Code runs in isolated Docker containers
- `code_execution_mode="safe"` ensures complete system isolation
- Automatic container lifecycle management
- Cross-platform compatibility and consistency

**Performance Features:**
- 120-second execution window for intensive calculations
- Up to 5 retry attempts for failed executions
- Comprehensive timeout and error management
- Detailed execution traces and performance monitoring

#### ğŸ“Š Code Generation Examples

**Mathematical Series Calculation:**
```python
# Generated code for Ï€ approximation
total = 0.0
for n in range(10000):
    if n % 2 == 0:
        total += 1 / (2 * n + 1)
    else:
        total -= 1 / (2 * n + 1)

result = total * 4
print(result)  # Output: 3.1414926535900345
```

#### ğŸ’¡ Example Usage

```bash
# Setup CrewAI CLI with Python 3.12
uv tool install crewai --python 3.12

# Create and setup project
crewai create crew crewai-coder
cd crewai-coder
crewai install

# Configure environment
cp .env.example .env
# Edit .env with OPENAI_API_KEY and CREWAI_TRACING_ENABLED=true

# Run code generation
crewai run

# Output: Complete Python code with execution results
# ğŸ³ Docker: Running code in Docker environment...
# ğŸ“Š Result: 3.1414926535900345 (Ï€ approximation)
```

#### ğŸ¯ Advanced Capabilities

- **Natural Language to Code**: Convert programming descriptions into executable Python
- **Mathematical Computing**: Handle complex calculations and series approximations
- **Secure Execution**: Docker-based isolation for code safety
- **Performance Optimization**: Configurable timeouts and retry mechanisms
- **Cross-Platform**: Consistent behavior across operating systems

#### ğŸ“Š Performance Benchmarks

- **Series Approximation**: 10,000 terms in <30 seconds
- **Docker Startup**: ~2-3 seconds container initialization
- **Memory Management**: Efficient resource usage in containers
- **Error Recovery**: Automatic retry logic for failed executions

#### ğŸš€ Production Features

- **Secure Execution**: Docker-based isolation for code safety
- **Performance Monitoring**: Detailed execution timing and resource usage
- **Error Handling**: Comprehensive timeout and failure management
- **Scalable Design**: Modular configuration for different coding tasks
- **Professional Output**: Production-ready code generation and validation

---

## ğŸ“ Learning Progression & Technical Skills

### ğŸ“š Foundations (Days 1-6)

#### Core Python Programming & Algorithmic Thinking

| Project | Skills Demonstrated | Complexity |
|---------|-------------------|------------|
| **Printing & Variables** | String formatting, type conversion, f-strings | â­ |
| **Data Types & Type System** | Primitive types, operators, type casting | â­â­ |
| **Tip Calculator** | Mathematical operations, user input, business logic | â­â­ |
| **Treasure Island Game** | Conditional logic, control flow, game development | â­â­â­ |
| **Rock-Paper-Scissors** | Randomization, arrays, game logic, ASCII art | â­â­â­ |
| **Password Generator** | Loops, string manipulation, security concepts | â­â­â­ |

### ğŸ”§ Intermediate Concepts (Days 7-12)

#### Advanced Programming Patterns & Problem Solving

| Project | Technical Skills | Applications |
|---------|------------------|-------------|
| **Hangman Game** | ASCII art, word lists, game state management | Game Development |
| **Caesar Cipher** | Encryption/decryption, modular arithmetic, text processing | Cryptography |
| **Dictionary Mastery** | Data structures, JSON-like operations, complex data handling | Data Management |
| **Function Design** | Return values, scope management, modular programming | Software Architecture |
| **Testing & Debugging** | pytest, error handling, code validation | Quality Assurance |
| **Scope Management** | Local/global variables, memory management, best practices | System Design |

---

## ğŸ’¼ Enterprise-Ready Skills Demonstrated

### ğŸ¯ Software Engineering Excellence

- **Clean Code Principles**: PEP 8 compliance, descriptive naming, modular design
- **Testing Methodology**: Unit tests, integration tests, TDD concepts
- **Version Control**: Git workflow, branching strategies, collaborative development
- **Documentation**: Comprehensive READMEs, code comments, API documentation

### ğŸ—ï¸ System Architecture

- **MVC/MVT Patterns**: Django's Model-View-Template architecture
- **RESTful Design**: Proper HTTP methods, status codes, resource modeling
- **Database Design**: Relational modeling, migrations, ORM optimization
- **Security Implementation**: Authentication, authorization, data validation

### ğŸš€ Modern Development Practices

- **Environment Management**: Virtual environments, dependency isolation
- **Configuration Management**: Environment variables, settings separation
- **API Development**: REST standards, serialization, error handling
- **Frontend Integration**: CORS, JWT, modern JavaScript/React patterns

### ğŸ¤– AI/ML Integration

- **LLM Integration**: Groq API, prompt engineering, response parsing
- **Real-time Processing**: Asynchronous operations, error handling
- **Data Processing**: File handling, PDF processing, text analysis
- **Scalable AI Architecture**: Modular design for AI features

---

## ğŸš€ Advanced AI Agent Systems

### 12. ğŸ¤– 32-LangGraph-Chat: Intelligent Chat System with Graph-Based Workflows

A sophisticated chat application built with LangGraph that demonstrates state management, graph-based agent workflows, and real-time conversational AI capabilities.

#### ğŸ¯ Core Features

- **ğŸ”„ StateGraph Architecture**: Graph-based agent workflow with state management
- **ğŸ’¬ Interactive Chat Interface**: Gradio-powered real-time chat UI
- **ï¿½ï¿½ Message Processing**: LangChain message types and validation
- **ğŸ“Š Graph Visualization**: Mermaid diagram generation and PNG export
- **âš¡ Real-time Processing**: Asynchronous message handling and response generation

#### ğŸ› ï¸ Technical Implementation

```python
class State(BaseModel):
    message: Annotated[list, add_messages]

def our_first_node(old_state: State) -> State:
    reply = f"{random.choice(nouns)} are {random.choice(adjectives)}"
    messages = [{"role": "assistant", "content": reply}]
    return State(message=messages)

graph = graph_builder.compile()
```

#### ğŸ“‹ Tech Stack

- **Framework**: LangGraph for graph-based agent workflows
- **AI/ML**: LangChain for message handling and validation
- **Frontend**: Gradio for web-based chat interface
- **State Management**: Pydantic models with annotated types
- **Visualization**: Mermaid diagrams and PNG export

#### ğŸ”„ Workflow Architecture

**Graph-Based Processing:**
1. **User Input** â†’ Gradio ChatInterface receives message
2. **State Creation** â†’ LangGraph State with message history
3. **Graph Processing** â†’ Node processes and generates response
4. **Response Return** â†’ AI message delivered to user

#### ğŸ“Š Performance Metrics

- **Response Time**: <50ms for message processing
- **Graph Compilation**: <100ms for workflow setup
- **UI Rendering**: <200ms for interface load
- **Memory Usage**: ~50MB baseline with minimal spikes

#### ğŸš€ Innovation Highlights

**State-of-the-Art Architecture:**
- LangGraph's StateGraph for complex agent orchestration
- Automatic message state management with type safety
- Visual graph representation for workflow debugging
- Modular node system for easy expansion

**Developer Experience:**
- UV-based dependency management for modern Python workflows
- Comprehensive error handling and validation
- Real-time debug information and graph visualization
- Extensible architecture for future enhancements

#### ğŸ”® Future Enhancements

- [ ] **OpenAI Integration**: GPT-4 powered intelligent responses
- [ ] **Memory System**: Persistent conversation history
- [ ] **Multi-Graph Support**: Multiple specialized agents
- [ ] **Voice Interface**: Speech-to-text and text-to-speech
- [ ] **Database Integration**: PostgreSQL/MongoDB for persistence


### 11. ğŸ—ï¸ 31-CrewAI-Engineering-Team: AI Multi-Agent Software Engineering System

A revolutionary multi-agent AI system powered by CrewAI that orchestrates specialized engineering agents to design, develop, test, and deploy complete Python applications from start to finish.

#### ğŸ¯ Core Features

- **ğŸ¤– Specialized Multi-Agent System**: 4 expert agents with distinct roles (Engineering Lead, Backend Engineer, Frontend Engineer, Test Engineer)
- **ğŸ”„ Complete Development Pipeline**: Sequential workflow from requirements to production-ready code
- **ğŸ’» Full-Stack Generation**: Backend Python code with Gradio UI frontend
- **ğŸ§ª Automated Testing**: Complete unit test suites with edge case validation
- **âš¡ Optimized Model Configuration**: OpenAI models balanced for cost and quality

#### ğŸ› ï¸ Technical Implementation

```python
@agent
def engineering_lead(self) -> Agent:
    return Agent(
        config=self.agents_config["engineering_lead"],
        verbose=True,
        allow_code_execution=True,
        max_execution_time=240,
    )
```

#### ğŸ“‹ Tech Stack

- **Framework**: CrewAI 1.8+ with multi-agent orchestration
- **AI/ML**: OpenAI GPT-4 Turbo, GPT-4o, GPT-4o-mini for optimized performance
- **Frontend**: Gradio for rapid UI development
- **Testing**: Python unittest framework with comprehensive coverage
- **Code Execution**: Docker-based secure code execution environment

#### ğŸ—ï¸ System Architecture

**Multi-Agent Workflow:**
1. **Engineering Lead**: Creates detailed system design and architecture
2. **Backend Engineer**: Implements complete Python backend with business logic
3. **Frontend Engineer**: Develops Gradio UI with full integration
4. **Test Engineer**: Generates comprehensive unit tests with edge cases

**Generated Application Example:**
```python
# Complete Trading System Generated
class Account:
    def __init__(self, username, initial_deposit):
        # Full implementation
    
    def buy_shares(self, symbol, quantity):
        # Trading logic with validation
```

#### ğŸ“Š Performance Metrics

- **Execution Time**: 3-8 minutes for complete application generation
- **Cost Efficiency**: ~$0.50-1.50 per complete application
- **Success Rate**: 100% functional applications with proper error handling
- **Test Coverage**: 17+ unit tests per application with edge case validation

#### ğŸ¯ Real-World Applications

- **ğŸ¦ Financial Systems**: Trading platforms, portfolio management, investment simulators
- **ğŸ›’ E-commerce**: Inventory systems, payment processing, shopping carts
- **ğŸ“Š Data Analytics**: Interactive dashboards, reporting tools, data visualization
- **ğŸ® Gaming**: Strategy games, business simulators, scoring systems

#### ğŸš€ Innovation Highlights

**Enterprise-Ready Code Generation:**
- Production-ready Python applications with proper error handling
- Complete UI/UX with Gradio interface
- Comprehensive testing with 100% feature coverage
- Scalable architecture following industry best practices

**Cost-Effective Development:**
- Reduces development time from days to minutes
- Optimized model selection for cost efficiency
- Automated testing eliminates manual QA efforts
- Consistent code quality across all generated applications


### 10. ğŸ§  26-Deep-Research: Multi-Agent Research System

A sophisticated multi-agent research system leveraging OpenAI Agents SDK for automated deep research with web search capabilities, real-time streaming, and comprehensive report generation.

#### ğŸ¯ Core Features

- **Multi-Agent Architecture**: Specialized agents for planning, searching, writing, and email delivery
- **Real-time Web Search**: Integration with OpenAI WebSearchTool for up-to-date information
- **Streaming Interface**: Gradio-based UI with real-time progress updates
- **Automated Reporting**: AI-powered report generation with markdown formatting
- **Email Integration**: Automatic email delivery of research results via Resend API
- **Trace Monitoring**: OpenAI platform integration for debugging and monitoring

#### ğŸ—ï¸ Technical Implementation

```python
# Multi-agent coordination with streaming
async def run(query: str):
    async for chunk in ResearchManager().run(query):
        yield chunk  # Real-time UI updates

# Specialized agent workflow
1. Planner Agent â†’ Research strategy
2. Search Agent â†’ Web information gathering  
3. Writer Agent â†’ Report synthesis
4. Email Agent â†’ Automated delivery
```

#### ğŸ› ï¸ Tech Stack

- **AI Framework**: OpenAI Agents SDK (v0.6.4+)
- **UI Framework**: Gradio (v6.3.0) with streaming support
- **Web Search**: OpenAI WebSearchTool integration
- **Email Service**: Resend API for automated delivery
- **Package Management**: UV for modern Python dependency management
- **Environment**: Python 3.14+ with async/await patterns

#### ğŸš€ Quick Start

```bash
# Clone and setup
git clone <repository>
cd 26-Deep-Research/deep_research

# Install dependencies
uv sync

# Configure environment
cp .env.example .env
# Edit .env with your API keys

# Run the research UI
uv run deep_research.py

# Or run CLI version
cd .. && uv run main.py
```

#### ğŸ“Š Advanced Features

- **Concurrent Search**: Parallel web searches with asyncio
- **Intelligent Planning**: AI-driven research strategy generation
- **Error Handling**: Robust exception management and fallbacks
- **Real-time Tracing**: OpenAI platform integration for debugging
- **Modular Design**: Extensible agent architecture for customization

#### ğŸ¨ User Experience

- **Interactive Interface**: Clean Gradio UI with real-time updates
- **Progress Tracking**: Live status updates during research process
- **Report Export**: Markdown-formatted research reports
- **Email Notifications**: Automatic delivery to specified recipients

---

## ğŸ› ï¸ Technical Stack Summary

### Backend Technologies

```yaml
Python: 3.8+
Django: 4.2
Django REST Framework: Latest
PostgreSQL: Production Ready
SQLite: Development
JWT: Simple JWT
Testing: pytest, pytest-django
```

### Frontend Technologies

```yaml
React: 18.2
Vite: Latest
Tailwind CSS: 3.4+
Shadcn/ui: Modern component library
Axios: HTTP client
React Router: Client-side routing
Testing: Vitest, React Testing Library
```

### AI & Machine Learning

```yaml
LLM: Meta Llama 3 70B
API: Groq Cloud Platform
Prompt Engineering: Custom implementations
Text Processing: NLP fundamentals
```

### Development Tools

```yaml
Version Control: Git
Environment: Python venv
Package Management: pip, npm
Code Quality: ESLint, PEP 8
Debugging: Django Debug Toolbar
```

---

## ğŸ“ˆ Project Metrics & Impact

### Code Quality Metrics

- **50+ Python programs** with increasing complexity
- **5 production-ready applications** with enterprise features
- **Comprehensive test coverage** across all major projects
- **Documentation-first approach** with detailed READMEs
- **Multi-language implementations** (Python, TypeScript, JavaScript)

### Technical Complexity

- **Multi-tier architecture** (Frontend, Backend, AI services)
- **Real-time AI integration** with production APIs
- **Security-first implementation** with JWT and data validation
- **Scalable design patterns** for enterprise applications
- **MCP Protocol implementation** for AI assistant integration
- **OAuth 2.0 authentication** with Auth0 and enterprise security
- **Cloudflare Workers deployment** for global serverless architecture
- **Remote MCP connections** with secure token management
- **Context engineering optimization** for AI efficiency
- **Multi-agent systems** with specialized task capabilities
- **Real-time communication** with WebSockets and stdio protocols
- **Cross-platform automation** with Playwright browser control
- **Multi-language development** (Python, TypeScript, JavaScript)
- **Enterprise-grade monitoring** and logging systems

### Learning Progression

- **Systematic skill building** from basics to advanced concepts
- **Project-based learning** with real-world applications
- **Modern tech stack** aligned with industry standards
- **Continuous improvement** with refactoring and optimization

---

## ğŸš€ Getting Started

### Prerequisites

```bash
# Python Environment
Python 3.8+
pip (latest)
virtualenv

# Node.js Environment (for React projects)
Node.js 16+
npm or yarn
```

### Quick Setup

```bash
# Clone the repository
git clone https://github.com/DanielGeek/python_projects.git
cd python_projects

# Explore daily exercises
ls 0*-day-*/

# Run flagship projects
cd 13-AIHR  # AI-Powered HR System
# or
cd 14-Django-React-Full-Stack-App  # Full-Stack App
# or
cd 16-MCP-meetings  # AI-Powered Meeting System
# or
cd 17-mcp-servers  # MCP Weather Servers
# or
cd 18-AI-agent  # AI Data Generator Agent
# or
cd 21-RAG-AI  # Advanced RAG System
# or
cd 25-openai-agent  # OpenAI Agents Automated SDR System
```

### Installation Examples

#### AI-Powered HR System

```bash
cd 13-AIHR
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
python manage.py migrate
python manage.py runserver
```

#### Django-React Full-Stack App

```bash
# Backend
cd 14-Django-React-Full-Stack-App/backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python manage.py migrate
python manage.py runserver

# Frontend (new terminal)
cd ../frontend
npm install
npm run dev
```

#### AI-Powered Meeting System

```bash
cd 16-MCP-meetings
uv sync
source .venv/bin/activate

# Terminal 1: MCP Server (AI processing)
uv run MCP_SERVER.py

# Terminal 2: Meeting API (orchestrator)
uv run MEETING_API.py
```

#### MCP Weather Servers & AI Integration

```bash
# Python Weather Server
cd 17-mcp-servers/02-weather-server-python
uv sync
uv run python test_weather.py
# Configure with Claude Desktop or Windsurf using README instructions

# TypeScript Weather Server
cd 17-mcp-servers/01-weather-server-typescript
npm install
npm run build
npm run test
# Configure with Claude Desktop or Windsurf using README instructions

# Auth0 MCP Server (Production)
cd 17-mcp-servers/09-remote-mcp-auth0/mcp-auth0-oidc
npm run build
npm run deploy
# Configure Claude Desktop with OAuth authentication

# Context Engineering
cd 17-mcp-servers/10-context-engineering-mcp
uv sync
fastmcp dev verbose_mcp_server.py
# Development with MCP Inspector

# Agent Skills
cd 17-mcp-servers/11-agent-skills
npm install
npm run dev
# Next.js development server

# AI Data Generator Agent
cd 18-AI-agent
uv sync
cp .env.example .env
# Edit .env with your Google AI API key
uv run main.py
# Start the AI agent

# Multi-Source Research Agent
cd 22-AI-Search-Agent
uv sync
cp .env.example .env
# Edit .env with Bright Data and Google API keys
uv run main.py
# Start the multi-source research agent

# Multi-LLM Evaluation System
cd 23-AI-Agent
uv sync
cp .env.example .env
# Edit .env with OpenAI and Google API keys
uv run main.py
# Compare responses from OpenAI, Gemini, and Ollama

# AI Career Assistant with Tool Use
cd 24-AI-Career-Assistant
uv sync
cp .env.example .env
# Edit .env with OpenAI and Pushover API keys
uv run main.py
# Launch professional career assistant with real-time notifications
```

---

## ğŸ§ª Testing & Quality Assurance

### Running Tests

```bash
# Django Projects
pytest  # AIHR Project
python manage.py test  # Django-React Backend

# React Frontend
npm test  # Frontend unit tests
npm run test:coverage  # Coverage reports

# AI-Powered Meeting System
uv run python test_mcp_client.py  # Test MCP server integration
curl http://localhost:8001/docs  # API documentation testing

# MCP Weather Servers
cd 17-mcp-servers/02-weather-server-python
uv run python test_weather.py  # Test Python MCP server

cd ../01-weather-server-typescript
npm run test  # Test TypeScript MCP server
mcp-inspector node build/index.js  # Interactive testing
```

### Code Quality Standards

- **PEP 8 Compliance**: All Python code follows style guidelines
- **ESLint Configuration**: JavaScript/React code quality
- **Type Safety**: PropTypes and TypeScript considerations
- **Documentation**: Comprehensive inline and external documentation

---

## ğŸ¯ Why This Portfolio Matters for Big Tech

### ğŸ”§ Technical Excellence

- **Full-Stack Proficiency**: End-to-end application development
- **Modern Architecture**: Microservices, REST APIs, SPAs
- **AI Integration**: Practical LLM implementation in production
- **Security-First**: Authentication, authorization, data protection

### ğŸš€ Innovation & Problem-Solving

- **AI-Powered Solutions**: Real-world AI integration beyond demos
- **Scalable Design**: Enterprise-ready architecture patterns
- **User-Centric Approach**: Responsive design, UX considerations
- **Performance Optimization**: Efficient database queries, frontend optimization

### ğŸ“ˆ Growth Potential

- **Continuous Learning**: Progressive skill development
- **Adaptability**: Multiple tech stacks and paradigms
- **Best Practices**: Industry-standard development workflows
- **Collaboration Ready**: Clean code, documentation, version control

---

## ğŸ“ Connect & Explore

### ğŸ”— Live Demonstrations Available Upon Request

### ğŸ“§ Contact for recruitment opportunities and technical discussions

### ğŸŒŸ Open to challenging roles in Full-Stack Development, AI Engineering, and Backend Systems

---


### 13. ğŸ” 33-LangGraph-Search: Advanced AI Search System with Tool Integration and Persistent Memory

A sophisticated AI-powered search application built with LangGraph that combines web search capabilities, push notifications, and persistent conversation memory. This project demonstrates advanced LangGraph features including state management, tool integration, conditional routing, and SQLite-based checkpointing for production-ready conversational AI systems.

#### ğŸ¯ Core Features

- **ğŸ” Intelligent Web Search**: Google Serper API integration for real-time web search
- **ğŸ“± Push Notifications**: Pushover integration for mobile notifications
- **ğŸ’¾ Persistent Memory**: SQLite-based conversation history and state persistence
- **ğŸ”„ Tool-Based Architecture**: Modular tool system with conditional routing
- **ğŸ§  State Management**: Advanced LangGraph state handling with checkpointing
- **ğŸ’¬ Interactive Chat Interface**: Gradio-powered real-time conversational UI
- **ğŸ“Š State Visualization**: Complete graph structure and state history debugging

#### ğŸ› ï¸ Technical Implementation

```python
class State(TypedDict):
    messages: Annotated[list, add_messages]

@tool
def search(query: str) -> str:
    """Useful for when you need more information from an online search."""
    return serper.run(query)

@tool
def send_push_notification(content: str, title: str = "Langchain Search Result") -> str:
    """Useful for when you want to send a push notification."""
    return push(content, title)

# SQLite-based persistent memory
conn = sqlite3.connect("db/memory.db", check_same_thread=False)
sql_memory = SqliteSaver(conn)
graph = graph_builder.compile(checkpointer=sql_memory)
```

#### ğŸ“‹ Tech Stack

- **Framework**: LangGraph for graph-based agent workflows with conditional routing
- **AI/ML**: GPT-4o with tool binding for intelligent decision making
- **Search**: Google Serper API for real-time web search
- **Notifications**: Pushover API for mobile notifications
- **Database**: SQLite with SqliteSaver for persistent state management
- **Frontend**: Gradio for web-based chat interface
- **Tools**: LangChain Core for tool integration and validation

#### ğŸ”„ Advanced Workflow Architecture

**Graph-Based Processing with Tool Routing:**
1. **User Input** â†’ Gradio ChatInterface receives message
2. **State Creation** â†’ LangGraph State with conversation history
3. **LLM Processing** â†’ GPT-4o with tool binding decides tool usage
4. **Conditional Routing** â†’ `tools_condition` routes to tools if needed
5. **Tool Execution** â†’ Search or Push Notification tools process
6. **Response Return** â†’ Updated conversation state delivered to user

**State Management with Persistence:**
```python
def chat(user_input: str, history):
    result = graph.invoke(
        {"messages": [{"role": "user", "content": user_input}]}, 
        config=config
    )
    
    # Real-time state debugging
    state = graph.get_state(config)
    history = list(graph.get_state_history(config))
    print("ğŸ“Š State:", state)
    print("ğŸ“œ History length:", len(history))
    
    return result["messages"][-1].content
```

#### ğŸ“Š Performance Metrics

- **LLM Processing**: 200-800ms depending on query complexity
- **Web Search**: 300-1500ms depending on search complexity
- **Push Notifications**: 100-300ms
- **Database Operations**: <50ms for state retrieval
- **Total Response**: 600-2500ms typical
- **Memory Usage**: ~100MB baseline + conversation history
- **Database Storage**: ~1KB per conversation turn

#### ğŸ¯ Real-World Applications

- **ğŸ¢ Research Assistants**: Automated web search with notification delivery
- **ğŸ”§ Development Tools**: Code documentation search with build notifications
- **ğŸ“Š Market Intelligence**: Real-time information gathering with alerts
- **ğŸ“š Educational Tools**: Research automation for students and educators
- **ğŸš¨ System Monitoring**: Error investigation with alert notifications

#### ğŸš€ Innovation Highlights

**State-of-the-Art Architecture:**
- LangGraph's conditional routing for intelligent tool selection
- SQLite-based persistent memory with msgpack serialization
- Real-time state debugging and history visualization
- Modular tool system with automatic LLM integration

**Developer Experience:**
- Comprehensive state debugging with console output
- Database inspection tools for conversation analysis
- Modular tool architecture for easy expansion
- Production-ready error handling and validation

#### ğŸ”® Future Enhancements

- [ ] **Multi-Search Support**: Multiple search engines (Bing, DuckDuckGo)
- [ ] **Advanced Filtering**: Search result filtering and ranking
- [ ] **Conversation Analytics**: Usage metrics and insights
- [ ] **Webhook Integration**: Custom notification endpoints
- [ ] **File Upload**: Document search and analysis
- [ ] **Voice Interface**: Speech-to-text and text-to-speech


### 13. ğŸŒ 34-LangGraph-Playwright: Advanced Web Scraping System

A sophisticated web scraping assistant that combines LangGraph with Playwright to extract content from any website, including news sites with anti-bot protection like CNN and BBC.

#### ğŸ¯ Key Features

- **Anti-Bot Bypass**: Uses stealth techniques to bypass modern anti-bot detection systems
- **Fresh Browser Context**: Creates isolated browser instances per request to avoid event loop conflicts
- **Smart Navigation**: Uses `domcontentloaded` wait strategy to avoid waiting for heavy JavaScript and ads
- **Real-time Content Extraction**: Extracts visible text from any website including CNN, BBC, and other protected sites
- **Push Notifications Integration**: Send extracted content via Pushover notifications
- **Interactive Chat Interface**: Natural language queries through Gradio chat UI

#### ğŸ› ï¸ Technical Implementation

```python
# Fresh browser context per request to avoid conflicts
@tool
async def get_webpage_content(url: str) -> str:
    """Fetch text content from any website including news sites"""
    from playwright.async_api import async_playwright
    
    playwright = await async_playwright().start()
    browser = await playwright.chromium.launch(headless=False)
    
    # Use domcontentloaded to avoid waiting for all resources
    await page.goto(url, wait_until="domcontentloaded", timeout=30000)
    await page.wait_for_timeout(3000)  # Wait for JS rendering
    
    text = await page.inner_text("body")
    
    # Cleanup
    await context.close()
    await browser.close()
    await playwright.stop()
    
    return text
```

#### ğŸ“‹ Tech Stack

- **AI Framework**: LangGraph with OpenAI GPT-4o-mini for intelligent tool selection
- **Web Automation**: Playwright async_api directly (bypasses LangChain toolkit limitations)
- **UI**: Gradio chat interface for natural language interaction
- **Notifications**: Pushover API for real-time alerts
- **Package Management**: UV for modern Python dependency management

#### ğŸš€ Anti-Bot Bypass Strategy

**The Problem**: Traditional scraping fails on modern news sites due to:
- Anti-bot detection systems (Cloudflare, DataDome)
- Heavy JavaScript content that never finishes loading
- Resource loading timeouts when waiting for all assets

**The Solution**:
- **`playwright.async_api`** directly instead of LangChain's toolkit
- **`wait_until="domcontentloaded"`** to wait only for HTML, not all resources
- **Fresh browser context** per request to avoid event loop conflicts
- **Realistic User-Agent** to avoid basic detection
- **3-second wait** after navigation for dynamic content rendering

#### ğŸ“Š Performance Metrics

- **CNN Extraction**: ~16 seconds (including browser launch)
- **Simple Sites**: ~5-8 seconds
- **Memory Usage**: ~200MB per request (cleaned up after)
- **Success Rate**: 95%+ on tested news sites
- **Browser Strategy**: Headful mode for better bypass capability

#### ğŸ’¡ Usage Examples

```bash
# Start the web scraping assistant
cd 34-langgraph-playwright
uv run main.py

# Available at http://127.0.0.1:7860

# Natural language queries:
User: "dame el titulo de CNN"
Bot: Extracts and displays CNN's main headline

User: "muÃ©strame el contenido de https://www.bbc.com/news"  
Bot: Navigates and extracts all text content

User: "enviame una notificacion con el headline de CNN"
Bot: Scrapes CNN and sends push notification
```

#### ğŸŒ Supported Sites

- âœ… **News Sites**: CNN, BBC, etc. (bypasses anti-bot protection)
- âœ… **Wikipedia**: Articles and content pages
- âœ… **Blogs**: Most blog platforms and CMS sites
- âœ… **Practice Sites**: quotes.toscrape.com, httpbin.org
- âœ… **General Websites**: Any HTML content on the web

#### ğŸ¯ Enterprise Applications

- **Content Monitoring**: Automated news and content tracking
- **Competitive Intelligence**: Extract competitor information
- **Research Automation**: Academic and market research data collection
- **Content Aggregation**: Build custom news feeds and summaries
- **SEO Analysis**: Extract and analyze website content

#### ğŸ—ï¸ Architecture

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Gradio UI     â”‚â”€â”€â”€â–¶â”‚   LangGraph   â”‚â”€â”€â”€â–¶â”‚ Playwright  â”‚
â”‚  (Chat Interface)â”‚    â”‚   (Agent)     â”‚    â”‚ (Browser)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  Pushover    â”‚
                       â”‚ Notificationsâ”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ğŸ”’ Security & Best Practices

- **Isolated Contexts**: Each request uses separate browser instance
- **No Persistent Data**: No cookies or sessions stored between requests
- **Automatic Cleanup**: Browser resources cleaned up after each extraction
- **Rate Limiting**: Built-in timeouts and error handling
- **User-Agent Spoofing**: Basic fingerprinting protection

---

### 14. ğŸ¤ 35-LangGraph-Sidekick: Multi-Agent Personal Co-worker

An intelligent multi-agent system that combines a Worker agent with an Evaluator agent to complete tasks with quality assurance. The system uses structured outputs and continuous feedback loops to ensure success criteria are met.

#### ğŸ¯ Key Features

- **Multi-Agent Architecture**: Worker agent executes tasks, Evaluator agent ensures quality
- **Structured Outputs**: Pydantic models for reliable agent communication
- **Success Criteria Tracking**: Define and validate completion criteria
- **Feedback Loop**: Continuous improvement through evaluator feedback
- **Playwright Integration**: Web scraping capabilities with anti-bot bypass
- **Interactive UI**: Gradio interface with success criteria input
- **Persistent Memory**: Thread-based conversation history

#### ğŸ› ï¸ Technical Implementation

```python
# Structured output for quality assurance
class EvaluatorOutput(BaseModel):
    feedback: str
    success_criteria_met: bool
    user_input_needed: bool

# Multi-agent state management
class State(TypedDict):
    messages: Annotated[List[Any], add_messages]
    success_criteria: str
    feedback_on_work: Optional[str]
    success_criteria_met: bool
    user_input_needed: bool
```

#### ğŸ“‹ Tech Stack

- **AI Framework**: LangGraph with OpenAI GPT-4o-mini
- **Multi-Agent System**: Worker + Evaluator agents with structured outputs
- **Web Automation**: Playwright async_api for web scraping
- **UI**: Gradio 6.x with success criteria input
- **Structured Data**: Pydantic models for agent communication
- **Package Management**: UV for modern Python dependency management

#### ğŸ”„ Multi-Agent Workflow

```text
START â†’ Worker â†’ Tools? â†’ Evaluator â†’ Success? â†’ END
          â†‘                              â†“
          â””â”€â”€â”€â”€â”€â”€â”€â”€ Feedback Loop â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ğŸ“Š Performance Metrics

- **Task Completion**: 85-95% success rate with proper criteria
- **Iteration Cycles**: 1-3 feedback loops per task average
- **Web Scraping**: ~16 seconds for CNN with anti-bot bypass
- **Memory Usage**: ~250MB per conversation thread
- **Response Time**: 2-5 seconds per agent evaluation

#### ğŸ’¡ Usage Examples

```bash
# Start the Sidekick system
cd 35-langgraph-sidekick
uv run main.py

# Available at http://127.0.0.1:7860

# Example workflow:
User Request: "Get me the main headline from CNN"
Success Criteria: "Response contains the current headline text"

# Process:
# 1. Worker scrapes CNN using Playwright
# 2. Evaluator checks if headline is present
# 3. If not met, provides feedback and worker tries again
# 4. Loop continues until criteria satisfied
```

#### ğŸ¯ Enterprise Applications

- **Quality Assurance**: Automated review and validation processes
- **Research Tasks**: Web scraping with content validation
- **Data Extraction**: Structured information gathering with verification
- **Content Creation**: Writing with quality criteria enforcement
- **Process Automation**: Multi-step tasks with approval loops

#### ğŸ—ï¸ Architecture

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    START     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Worker     â”‚â—„â”€â”€â”€â”€â”€â”
â”‚   Agent      â”‚      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
       â”‚              â”‚
       â–¼              â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
  â”‚ Tools? â”‚â”€â”€Yesâ”€â”€â–ºâ”Œâ”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜        â”‚ Playwrightâ”‚
      â”‚             â”‚   Tools   â”‚
      No            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                    â”‚
      â–¼                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  Evaluator   â”‚          â”‚
â”‚   Agent      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
  â”‚ Success? â”‚
  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
       â”‚
    â”Œâ”€â”€â”´â”€â”€â”
    â”‚ Yes â”‚â”€â”€â–º END
    â””â”€â”€â”€â”€â”€â”˜
       â”‚
      No
       â”‚
    (Loop back to Worker)
```

#### ğŸ” Key Components

### 1. Worker Agent

```python
def worker(state: State) -> Dict[str, Any]:
    """
    - Receives task and success criteria
    - Uses tools to complete assignment
    - Can ask clarifying questions
    - Returns response for evaluation
    """
```

### 2. Evaluator Agent

```python
def evaluator(state: State) -> State:
    """
    - Reviews worker's response
    - Checks against success criteria
    - Provides structured feedback
    - Decides: continue, end, or need user input
    """
```

### 3. Structured Output System

```python
class EvaluatorOutput(BaseModel):
    feedback: str  # What needs improvement
    success_criteria_met: bool  # Task complete?
    user_input_needed: bool  # Need clarification?
```

#### ğŸ® Interactive Features

- **Success Criteria Input**: Define explicit completion requirements
- **Real-time Feedback**: See both worker output and evaluation
- **Thread Management**: Persistent conversation history
- **Reset Functionality**: Start fresh tasks
- **Progress Visualization**: Track iteration cycles

#### ğŸ”’ Security & Best Practices

- **Structured Communication**: Pydantic models prevent malformed data
- **Isolated Execution**: Each task runs in separate context
- **Input Validation**: Success criteria must be specific and measurable
- **Error Handling**: Graceful failure with user feedback
- **Resource Cleanup**: Automatic cleanup of browser instances

#### ğŸ“ Learning Points Demonstrated

- **Multi-agent systems** with specialized roles
- **Structured outputs** using Pydantic
- **Feedback loops** for iterative improvement
- **State management** in LangGraph
- **Conditional routing** based on agent decisions
- **Tool integration** with async operations
- **Quality assurance patterns** in AI systems

---

## ğŸ“„ License

All projects are open source and available under the MIT License - see individual project licenses for details.

---

> **ğŸ’¡ Note**: This portfolio represents a journey of continuous learning and technical growth. Each project builds upon previous knowledge, demonstrating the ability to master new technologies and apply them to solve real-world problems.

**ğŸš€ Ready to bring this expertise to your team!**
