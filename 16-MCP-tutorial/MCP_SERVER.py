#!/usr/bin/env python3
"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MCP SERVER - Servidor de Procesamiento con IA para Reuniones
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Servidor FastMCP que expone herramientas de IA para procesar reuniones:
- TranscripciÃ³n de audio/video
- TraducciÃ³n de texto
- GeneraciÃ³n de resÃºmenes
- ExtracciÃ³n de acciones y tareas
- AnÃ¡lisis de sentimiento
- GeneraciÃ³n de minutas

Este servidor NO guarda datos, solo procesa y retorna resultados.
La persistencia debe manejarse en la API Gateway.

Funciona con diferentes modelos:
- OpenAI Whisper para transcripciÃ³n
- OpenAI GPT-4 para resÃºmenes, acciones, etc.
- Google Gemini Pro (opcional)

Requerimientos:
- fastmcp
- openai
- python-dotenv
"""

import os
import json
import time
from typing import Dict, List, Any, Optional, Union
from datetime import datetime
from fastmcp import FastMCP
from starlette.middleware import Middleware
from starlette.middleware.cors import CORSMiddleware
import requests
from dotenv import load_dotenv
import tempfile
import subprocess
import logging
import uuid

# Importar modelos de IA
import openai
from openai import OpenAI

# Cargar variables de entorno
load_dotenv()

# ConfiguraciÃ³n de logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("mcp_server.log")
    ]
)
logger = logging.getLogger(__name__)

# ConfiguraciÃ³n de OpenAI
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ConfiguraciÃ³n de transcripciÃ³n
TRANSCRIPTION_MODEL = os.getenv("TRANSCRIPTION_MODEL", "openai")  # openai, assemblyai, google
OPENAI_WHISPER_MODEL = os.getenv("OPENAI_WHISPER_MODEL", "whisper-1")
ASSEMBLYAI_API_KEY = os.getenv("ASSEMBLYAI_API_KEY", "")
GOOGLE_SPEECH_KEY = os.getenv("GOOGLE_SPEECH_KEY", "")

# ConfiguraciÃ³n de LLM
LLM_MODEL = os.getenv("LLM_MODEL", "openai")  # openai, google
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4")
GOOGLE_MODEL = os.getenv("GOOGLE_MODEL", "gemini-pro")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY", "")

# Otras configuraciones
MAX_RETRIES = 3
RETRY_DELAY = 2  # segundos

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIONES AUXILIARES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def download_video(video_url: str) -> str:
    """
    Descargar video desde URL
    
    Args:
        video_url: URL del video
        
    Returns:
        str: Ruta local del video descargado
    """
    logger.info(f"ğŸ“¥ Descargando video: {video_url}")
    
    # Si es una ruta local (file://), extraer la ruta
    if video_url.startswith("file://"):
        local_path = video_url[7:]
        if os.path.exists(local_path):
            return local_path
    
    # Crear directorio temporal
    temp_dir = tempfile.mkdtemp()
    temp_path = os.path.join(temp_dir, f"video_{uuid.uuid4()}.mp4")
    
    try:
        if "zoom.us" in video_url or "drive.google.com" in video_url or "onedrive" in video_url:
            # Para URLs de Zoom/Google/Microsoft, usar requests
            response = requests.get(video_url, stream=True)
            with open(temp_path, "wb") as f:
                for chunk in response.iter_content(chunk_size=1024):
                    if chunk:
                        f.write(chunk)
        else:
            # Usar youtube-dl para servicios de streaming
            subprocess.run(
                ["yt-dlp", video_url, "-o", temp_path],
                check=True
            )
        
        logger.info(f"âœ… Video descargado: {temp_path}")
        return temp_path
    except Exception as e:
        logger.error(f"âŒ Error descargando video: {str(e)}")
        raise Exception(f"Error descargando video: {str(e)}")

def extract_audio(video_path: str) -> str:
    """
    Extraer audio de un video
    
    Args:
        video_path: Ruta del video
        
    Returns:
        str: Ruta del archivo de audio
    """
    logger.info(f"ğŸ”Š Extrayendo audio de: {video_path}")
    
    # Crear archivo de salida
    audio_path = video_path.rsplit(".", 1)[0] + ".mp3"
    
    # Extraer audio usando FFmpeg
    try:
        subprocess.run(
            [
                "ffmpeg", "-y",
                "-i", video_path,
                "-vn",  # Sin video
                "-acodec", "libmp3lame",
                "-q:a", "4",
                audio_path
            ],
            check=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        
        logger.info(f"âœ… Audio extraÃ­do: {audio_path}")
        return audio_path
    except Exception as e:
        logger.error(f"âŒ Error extrayendo audio: {str(e)}")
        raise Exception(f"Error extrayendo audio: {str(e)}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TRANSCRIPCIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def transcribe_audio_openai(audio_path: str) -> str:
    """
    Transcribir audio usando OpenAI Whisper
    
    Args:
        audio_path: Ruta del archivo de audio
        
    Returns:
        str: TranscripciÃ³n
    """
    logger.info(f"ğŸ”¤ Transcribiendo con OpenAI Whisper: {audio_path}")
    
    retries = 0
    while retries < MAX_RETRIES:
        try:
            with open(audio_path, "rb") as audio_file:
                transcript = openai_client.audio.transcriptions.create(
                    model=OPENAI_WHISPER_MODEL,
                    file=audio_file
                )
            
            logger.info(f"âœ… TranscripciÃ³n completada: {len(transcript.text)} caracteres")
            return transcript.text
        except Exception as e:
            logger.error(f"âŒ Error en transcripciÃ³n (intento {retries+1}/{MAX_RETRIES}): {str(e)}")
            retries += 1
            time.sleep(RETRY_DELAY)
    
    raise Exception("FallÃ³ la transcripciÃ³n despuÃ©s de varios intentos")

def transcribe_audio_assemblyai(audio_path: str) -> str:
    """
    Transcribir audio usando AssemblyAI
    
    Args:
        audio_path: Ruta del archivo de audio
        
    Returns:
        str: TranscripciÃ³n
    """
    if not ASSEMBLYAI_API_KEY:
        raise Exception("API Key de AssemblyAI no configurada")
    
    logger.info(f"ğŸ”¤ Transcribiendo con AssemblyAI: {audio_path}")
    
    # Subir archivo
    headers = {
        "authorization": ASSEMBLYAI_API_KEY,
        "content-type": "application/json"
    }
    
    # Leer archivo
    with open(audio_path, "rb") as f:
        audio_data = f.read()
    
    # Subir
    upload_url_response = requests.post(
        "https://api.assemblyai.com/v2/upload",
        headers=headers,
        data=audio_data
    )
    
    if upload_url_response.status_code != 200:
        raise Exception(f"Error subiendo audio: {upload_url_response.text}")
    
    upload_url = upload_url_response.json()["upload_url"]
    
    # Iniciar transcripciÃ³n
    transcript_response = requests.post(
        "https://api.assemblyai.com/v2/transcript",
        headers=headers,
        json={"audio_url": upload_url}
    )
    
    if transcript_response.status_code != 200:
        raise Exception(f"Error iniciando transcripciÃ³n: {transcript_response.text}")
    
    transcript_id = transcript_response.json()["id"]
    
    # Polling para esperar resultado
    while True:
        polling_response = requests.get(
            f"https://api.assemblyai.com/v2/transcript/{transcript_id}",
            headers=headers
        )
        
        if polling_response.status_code != 200:
            raise Exception(f"Error consultando transcripciÃ³n: {polling_response.text}")
        
        status = polling_response.json()["status"]
        
        if status == "completed":
            text = polling_response.json()["text"]
            logger.info(f"âœ… TranscripciÃ³n completada: {len(text)} caracteres")
            return text
        elif status == "error":
            raise Exception(f"Error en transcripciÃ³n: {polling_response.json().get('error')}")
        
        time.sleep(3)

def transcribe_audio(audio_path: str) -> str:
    """
    Transcribir audio con el modelo configurado
    
    Args:
        audio_path: Ruta del archivo de audio
        
    Returns:
        str: TranscripciÃ³n
    """
    if TRANSCRIPTION_MODEL == "assemblyai" and ASSEMBLYAI_API_KEY:
        return transcribe_audio_assemblyai(audio_path)
    else:
        # Usar OpenAI por defecto
        return transcribe_audio_openai(audio_path)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TRADUCCIÃ“N Y PROCESAMIENTO DE TEXTO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def translate_text_openai(text: str, target_language: str) -> str:
    """
    Traducir texto usando OpenAI
    
    Args:
        text: Texto a traducir
        target_language: Idioma destino (ej: "es", "en", "fr")
        
    Returns:
        str: Texto traducido
    """
    logger.info(f"ğŸŒ Traduciendo a {target_language} usando OpenAI")
    
    language_names = {
        "es": "espaÃ±ol",
        "en": "inglÃ©s",
        "fr": "francÃ©s",
        "de": "alemÃ¡n",
        "it": "italiano",
        "pt": "portuguÃ©s",
        "ru": "ruso",
        "zh": "chino",
        "ja": "japonÃ©s",
        "ko": "coreano"
    }
    
    target = language_names.get(target_language, target_language)
    
    prompt = f"Traduce el siguiente texto al {target}:\n\n{text}"
    
    response = openai_client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[
            {"role": "system", "content": f"Eres un traductor profesional. Traduce el texto al {target} manteniendo el formato y sentido original."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3
    )
    
    translation = response.choices[0].message.content.strip()
    logger.info(f"âœ… TraducciÃ³n completada: {len(translation)} caracteres")
    
    return translation

def translate_text(text: str, target_language: str) -> str:
    """
    Traducir texto con el modelo configurado
    
    Args:
        text: Texto a traducir
        target_language: Idioma destino
        
    Returns:
        str: Texto traducido
    """
    # Por ahora solo implementamos OpenAI
    return translate_text_openai(text, target_language)

def summarize_text_openai(transcript: str) -> str:
    """
    Resumir texto usando OpenAI
    
    Args:
        transcript: TranscripciÃ³n a resumir
        
    Returns:
        str: Resumen
    """
    logger.info("ğŸ“ Generando resumen con OpenAI")
    
    # Verificar longitud y dividir si es necesario
    if len(transcript) > 80000:  # LÃ­mite aproximado para GPT-4
        logger.info("âš ï¸ TranscripciÃ³n demasiado larga, dividiendo...")
        # Dividir en partes y resumir cada una
        parts = [transcript[i:i+80000] for i in range(0, len(transcript), 80000)]
        summaries = []
        
        for i, part in enumerate(parts):
            logger.info(f"Resumiendo parte {i+1}/{len(parts)}...")
            part_summary = summarize_text_openai(part)
            summaries.append(part_summary)
        
        # Juntar resÃºmenes y hacer un meta-resumen
        combined = "\n\n".join(summaries)
        return summarize_text_openai(combined)
    
    response = openai_client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[
            {"role": "system", "content": "Eres un asistente experto en crear resÃºmenes ejecutivos concisos pero completos. Resume la transcripciÃ³n de la reuniÃ³n destacando los puntos clave, decisiones y prÃ³ximos pasos."},
            {"role": "user", "content": f"Resume esta transcripciÃ³n de reuniÃ³n:\n\n{transcript}"}
        ],
        temperature=0.3
    )
    
    summary = response.choices[0].message.content.strip()
    logger.info(f"âœ… Resumen completado: {len(summary)} caracteres")
    
    return summary

def summarize_meeting(transcript: str) -> str:
    """
    Resumir reuniÃ³n con el modelo configurado
    
    Args:
        transcript: TranscripciÃ³n a resumir
        
    Returns:
        str: Resumen
    """
    # Por ahora solo implementamos OpenAI
    return summarize_text_openai(transcript)

def extract_action_items_openai(transcript: str) -> str:
    """
    Extraer elementos de acciÃ³n usando OpenAI
    
    Args:
        transcript: TranscripciÃ³n
        
    Returns:
        str: Elementos de acciÃ³n en formato estructurado
    """
    logger.info("ğŸ“‹ Extrayendo acciones con OpenAI")
    
    response = openai_client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[
            {"role": "system", "content": "Eres un asistente experto en identificar elementos de acciÃ³n concretos en transcripciones de reuniones. Extrae todos los elementos de acciÃ³n mencionados, incluyendo quiÃ©n es responsable, quÃ© debe hacer y cualquier fecha lÃ­mite mencionada. Presenta los resultados en una lista clara y estructurada."},
            {"role": "user", "content": f"Extrae los elementos de acciÃ³n de esta transcripciÃ³n de reuniÃ³n:\n\n{transcript}"}
        ],
        temperature=0.3
    )
    
    actions = response.choices[0].message.content.strip()
    logger.info(f"âœ… ExtracciÃ³n de acciones completada: {len(actions)} caracteres")
    
    return actions

def extract_action_items(transcript: str) -> str:
    """
    Extraer elementos de acciÃ³n con el modelo configurado
    
    Args:
        transcript: TranscripciÃ³n
        
    Returns:
        str: Elementos de acciÃ³n
    """
    # Por ahora solo implementamos OpenAI
    return extract_action_items_openai(transcript)

def analyze_sentiment_openai(transcript: str) -> Dict:
    """
    Analizar sentimiento usando OpenAI
    
    Args:
        transcript: TranscripciÃ³n
        
    Returns:
        Dict: AnÃ¡lisis de sentimiento
    """
    logger.info("ğŸ” Analizando sentimiento con OpenAI")
    
    response = openai_client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[
            {"role": "system", "content": "Eres un analista experto de sentimiento y tono en reuniones. Analiza la transcripciÃ³n y proporciona un anÃ¡lisis del sentimiento general (positivo, neutro, negativo), nivel de confianza (0.0-1.0), y 3-5 insights clave sobre el tono, nivel de participaciÃ³n y dinÃ¡mica de la reuniÃ³n."},
            {"role": "user", "content": f"Analiza el sentimiento de esta transcripciÃ³n de reuniÃ³n y devuelve el resultado en formato JSON con los campos overall_sentiment, confidence y key_insights:\n\n{transcript}"}
        ],
        temperature=0.3,
        response_format={"type": "json_object"}
    )
    
    sentiment_json = response.choices[0].message.content.strip()
    sentiment = json.loads(sentiment_json)
    logger.info("âœ… AnÃ¡lisis de sentimiento completado")
    
    return sentiment

def analyze_sentiment(transcript: str) -> Dict:
    """
    Analizar sentimiento con el modelo configurado
    
    Args:
        transcript: TranscripciÃ³n
        
    Returns:
        Dict: AnÃ¡lisis de sentimiento
    """
    # Por ahora solo implementamos OpenAI
    return analyze_sentiment_openai(transcript)

def generate_meeting_minutes_openai(transcript: str) -> str:
    """
    Generar minutas de reuniÃ³n usando OpenAI
    
    Args:
        transcript: TranscripciÃ³n
        
    Returns:
        str: Minutas en formato estructurado
    """
    logger.info("ğŸ“„ Generando minutas con OpenAI")
    
    # Obtener resumen
    summary = summarize_text_openai(transcript)
    
    # Extraer acciones
    actions = extract_action_items_openai(transcript)
    
    # Analizar sentimiento
    sentiment = analyze_sentiment_openai(transcript)
    
    # Generar minutas
    minutes = f"""
# ğŸ“ MINUTAS DE REUNIÃ“N
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## ğŸ“‹ RESUMEN:
{summary}

## âœ… ELEMENTOS DE ACCIÃ“N:
{actions}

"""
    
    minutes += f"""
    
ğŸ“Š ANÃLISIS DE SENTIMIENTO:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ Sentimiento general: {sentiment['overall_sentiment']}
â€¢ Confianza: {sentiment['confidence']:.1%}

ğŸ“ˆ Insights clave:
"""
    
    for insight in sentiment['key_insights']:
        minutes += f"    â€¢ {insight}\n"
    
    minutes += "\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
    
    return minutes

def generate_meeting_minutes(transcript: str) -> str:
    """
    Generar minutas con el modelo configurado
    
    Args:
        transcript: TranscripciÃ³n
        
    Returns:
        str: Minutas
    """
    # Por ahora solo implementamos OpenAI
    return generate_meeting_minutes_openai(transcript)

def process_transcript_chunk(meeting_id: str, transcript_chunk: str, platform: str) -> Dict:
    """
    Procesar chunk de transcripciÃ³n en tiempo real
    
    Args:
        meeting_id: ID de la reuniÃ³n
        transcript_chunk: Fragmento de transcripciÃ³n
        platform: Plataforma (zoom, google_meet, teams)
        
    Returns:
        Dict: Resultado del procesamiento
    """
    logger.info(f"ğŸ“„ Procesando chunk de transcripciÃ³n para reuniÃ³n {meeting_id}")
    
    # En un sistema completo, podrÃ­amos:
    # 1. Guardar en una base de datos en tiempo real
    # 2. Actualizar un resumen incremental
    # 3. Identificar acciones importantes
    
    # VersiÃ³n simple para demostraciÃ³n:
    response = openai_client.chat.completions.create(
        model="gpt-3.5-turbo",  # Modelo mÃ¡s rÃ¡pido para procesamiento en tiempo real
        messages=[
            {"role": "system", "content": "Identifica cualquier decisiÃ³n importante o elemento de acciÃ³n en este fragmento de transcripciÃ³n. Si no hay ninguno, responde con 'No se identificaron elementos importantes'."},
            {"role": "user", "content": transcript_chunk}
        ],
        temperature=0.3,
        max_tokens=100
    )
    
    analysis = response.choices[0].message.content.strip()
    
    return {
        "meeting_id": meeting_id,
        "platform": platform,
        "chunk_length": len(transcript_chunk),
        "timestamp": datetime.now().isoformat(),
        "analysis": analysis
    }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HERRAMIENTAS MCP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def transcribe_audio_tool(video_url: str) -> str:
    """
    Herramienta MCP para transcribir audio/video
    
    Args:
        video_url: URL del video/audio
        
    Returns:
        str: TranscripciÃ³n
    """
    try:
        # Descargar video
        video_path = download_video(video_url)
        
        # Extraer audio
        audio_path = extract_audio(video_path)
        
        # Transcribir audio
        transcript = transcribe_audio(audio_path)
        
        # Limpiar archivos temporales (opcional)
        # os.unlink(video_path)
        # os.unlink(audio_path)
        
        return transcript
    except Exception as e:
        logger.error(f"âŒ Error en herramienta transcribe_audio: {str(e)}")
        return f"Error: {str(e)}"

def translate_text_tool(text: str, target_language: str) -> str:
    """
    Herramienta MCP para traducir texto
    
    Args:
        text: Texto a traducir
        target_language: Idioma destino
        
    Returns:
        str: Texto traducido
    """
    try:
        return translate_text(text, target_language)
    except Exception as e:
        logger.error(f"âŒ Error en herramienta translate_text: {str(e)}")
        return f"Error: {str(e)}"

def summarize_meeting_tool(transcript: str) -> str:
    """
    Herramienta MCP para resumir reuniÃ³n
    
    Args:
        transcript: TranscripciÃ³n
        
    Returns:
        str: Resumen
    """
    try:
        return summarize_meeting(transcript)
    except Exception as e:
        logger.error(f"âŒ Error en herramienta summarize_meeting: {str(e)}")
        return f"Error: {str(e)}"

def extract_action_items_tool(transcript: str) -> str:
    """
    Herramienta MCP para extraer elementos de acciÃ³n
    
    Args:
        transcript: TranscripciÃ³n
        
    Returns:
        str: Elementos de acciÃ³n
    """
    try:
        return extract_action_items(transcript)
    except Exception as e:
        logger.error(f"âŒ Error en herramienta extract_action_items: {str(e)}")
        return f"Error: {str(e)}"

def analyze_sentiment_tool(transcript: str) -> Dict:
    """
    Herramienta MCP para analizar sentimiento
    
    Args:
        transcript: TranscripciÃ³n
        
    Returns:
        Dict: AnÃ¡lisis de sentimiento
    """
    try:
        return analyze_sentiment(transcript)
    except Exception as e:
        logger.error(f"âŒ Error en herramienta analyze_sentiment: {str(e)}")
        return {"error": str(e)}

def generate_meeting_minutes_tool(transcript: str) -> str:
    """
    Herramienta MCP para generar minutas
    
    Args:
        transcript: TranscripciÃ³n
        
    Returns:
        str: Minutas
    """
    try:
        return generate_meeting_minutes(transcript)
    except Exception as e:
        logger.error(f"âŒ Error en herramienta generate_meeting_minutes: {str(e)}")
        return f"Error: {str(e)}"

def process_transcript_chunk_tool(meeting_id: str, transcript_chunk: str, platform: str) -> Dict:
    """
    Herramienta MCP para procesar chunk de transcripciÃ³n
    
    Args:
        meeting_id: ID de la reuniÃ³n
        transcript_chunk: Fragmento de transcripciÃ³n
        platform: Plataforma (zoom, google_meet, teams)
        
    Returns:
        Dict: Resultado del procesamiento
    """
    try:
        return process_transcript_chunk(meeting_id, transcript_chunk, platform)
    except Exception as e:
        logger.error(f"âŒ Error en herramienta process_transcript_chunk: {str(e)}")
        return {"error": str(e)}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIÃ“N DE FASTMCP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Crear instancia de FastMCP con stateless_http=True para evitar problemas de session ID
mcp = FastMCP("Meeting Processor AI", stateless_http=True)

# Registrar herramientas usando decoradores
@mcp.tool()
def transcribe_audio(video_url: str) -> str:
    """Transcribe audio/video from URL to text"""
    return transcribe_audio_tool(video_url)

@mcp.tool()
def translate_text(text: str, target_language: str = "es") -> str:
    """Translate text to another language"""
    return translate_text_tool(text, target_language)

@mcp.tool(name="summarize_meeting")
def summarize_meeting_mcp(transcript: str) -> dict:
    """Generate a concise summary of meeting transcript"""
    try:
        # Llamar a la funciÃ³n de implementaciÃ³n real
        result = summarize_text_openai(transcript)
        return {
            "success": True,
            "summary": result,
            "transcript_length": len(transcript)
        }
    except Exception as e:
        logger.error(f"âŒ Error en herramienta summarize_meeting: {str(e)}")
        
        # Parsear error de OpenAI si es posible
        error_dict = {
            "success": False,
            "error_type": type(e).__name__,
            "error_message": str(e)
        }
        
        # Si es un error de OpenAI, extraer detalles
        if hasattr(e, 'response'):
            try:
                error_dict["status_code"] = e.response.status_code
                error_dict["error_details"] = e.response.json()
            except:
                pass
        
        return error_dict

@mcp.tool()
def extract_action_items(transcript: str) -> str:
    """Extract action items from meeting transcript"""
    return extract_action_items_tool(transcript)

@mcp.tool()
def analyze_sentiment(transcript: str) -> str:
    """Analyze sentiment and tone of meeting transcript"""
    return analyze_sentiment_tool(transcript)

@mcp.tool()
def generate_meeting_minutes(transcript: str) -> str:
    """Generate comprehensive meeting minutes"""
    return generate_meeting_minutes_tool(transcript)

@mcp.tool()
def process_transcript_chunk(meeting_id: str, transcript_chunk: str, platform: str) -> str:
    """Process a chunk of transcription in real-time"""
    return process_transcript_chunk_tool(meeting_id, transcript_chunk, platform)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NOTA IMPORTANTE SOBRE DOCUMENTACIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MCP usa JSON-RPC 2.0, NO tiene Swagger automÃ¡tico como FastAPI.
# La documentaciÃ³n se proporciona en el README.md
#
# Para usar el MCP Server:
# POST http://localhost:8000/mcp
# Body: {"jsonrpc": "2.0", "id": 1, "method": "tools/call", "params": {...}}
#
# Herramientas disponibles:
# - transcribe_audio(video_url)
# - translate_text(text, target_language)
# - summarize_meeting(transcript)
# - extract_action_items(transcript)
# - analyze_sentiment(transcript)
# - generate_meeting_minutes(transcript)
# - process_transcript_chunk(meeting_id, transcript_chunk, platform)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


if __name__ == "__main__":
    print("ğŸš€ Iniciando MCP Meeting Processor Pro...")
    print()
    print("ğŸ“¡ Endpoint MCP:")
    print("  POST http://localhost:8001/mcp")
    print("  Protocolo: JSON-RPC 2.0")
    print()
    print("ğŸ“‹ Herramientas disponibles:")
    print("  â€¢ transcribe_audio(video_url)")
    print("  â€¢ translate_text(text, target_language)")
    print("  â€¢ summarize_meeting(transcript)")
    print("  â€¢ extract_action_items(transcript)")
    print("  â€¢ analyze_sentiment(transcript)")
    print("  â€¢ generate_meeting_minutes(transcript)")
    print("  â€¢ process_transcript_chunk(meeting_id, transcript_chunk, platform)")
    print()
    print("ğŸ”— Modelos configurados:")
    print(f"  â€¢ TranscripciÃ³n: {TRANSCRIPTION_MODEL}")
    print(f"  â€¢ LLM: {LLM_MODEL} ({OPENAI_MODEL if LLM_MODEL == 'openai' else GOOGLE_MODEL})")
    print()
    print("ğŸ“š DocumentaciÃ³n completa en README.md")
    print()
    
    # Iniciar servidor
    mcp.run(
        transport="http",
        host="0.0.0.0",
        port=8001,
        middleware=[
            Middleware(
                CORSMiddleware,
                allow_origins=["*"],
                allow_credentials=True,
                allow_methods=["*"],
                allow_headers=["*"],
                expose_headers=["mcp-session-id", "Mcp-Session-Id"]  # Exponer header de sesiÃ³n para CORS
            )
        ]
    )
